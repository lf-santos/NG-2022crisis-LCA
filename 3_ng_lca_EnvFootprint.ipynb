{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental Footprint NG supply-demand scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import pprint\n",
    "import warnings\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "from string import ascii_uppercase\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.stats import pearsonr, norm\n",
    "import brightway2 as bw\n",
    "\n",
    "from ng_lca_toolbox import result2df, plot_proc_contrib, excel2ngScenarioLCA\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "LCAResult = namedtuple(\"LCAResult\", [\"demand\", \"method\", \"score\"])\n",
    "\n",
    "COLORS = [\"#66c2a5\", \"#fc8d62\", \"#ffd92f\", \"#8da0cb\", \"#e78ac3\"]\n",
    "SCENARIOS = [\"Base\", \"REPowerEU\", \"Aftermath\", \"Coal\", \"Clean\"]\n",
    "supply_scenario_y2021, supply_scenario_y2022, supply_scenario_alternative = (\n",
    "    \"y2021_mid\",\n",
    "    \"y2022_mid\",\n",
    "    \"alternative_mid\",\n",
    ")\n",
    "\n",
    "pprinter = pprint.PrettyPrinter(indent=4).pprint\n",
    "\n",
    "BW_PROJECT = \"NG_2022crisis_LCA\"\n",
    "DB_NAME = \"ecoinvent 3.9.1 cutoff, natural gas scenario EU27\"\n",
    "\n",
    "bw.projects.set_current(BW_PROJECT)  # Accessing the project\n",
    "ei_ng_db = bw.Database(DB_NAME)\n",
    "\n",
    "save_fig = False\n",
    "save_tables = False\n",
    "\n",
    "PATH2PICKLES = \"./data/persisted_files/\"\n",
    "if os.path.exists(PATH2PICKLES) is False:\n",
    "    os.makedirs(PATH2PICKLES)\n",
    "PATH2RESULTS = \"./data/results/\"\n",
    "if os.path.exists(PATH2RESULTS) is False:\n",
    "    os.makedirs(PATH2RESULTS)\n",
    "\n",
    "DO_LCA = False\n",
    "LCA_PATH = PATH2PICKLES + \"scenario_lca.pickle\"\n",
    "\n",
    "DO_PROC_CONTRIB = False\n",
    "PROC_CONTRIB_PATH = PATH2PICKLES + \"scenario_proc_contrib.pickle\"\n",
    "\n",
    "RUN_MC = False\n",
    "SKIP_MC = []\n",
    "N_mc = 1000\n",
    "MC_PATH = PATH2PICKLES + f\"monte_carlo_{N_mc}_ite.pickle\"\n",
    "MC_PATH_LCA_ONLY = PATH2PICKLES + \"monte_carlo_LCA_only.pickle\"\n",
    "\n",
    "VERBOSE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting parameters\n",
    "from matplotlib.ticker import (\n",
    "    ScalarFormatter,\n",
    "    FuncFormatter,\n",
    "    AutoMinorLocator,\n",
    "    LogLocator,\n",
    ")\n",
    "from matplotlib import ticker\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.markers import MarkerStyle\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "\n",
    "fig_length = {\n",
    "    1: 3.50394,  # 1 column\n",
    "    1.5: 5.35433,  # 1.5 columns\n",
    "    2: 7.20472,\n",
    "}  # 2 columns\n",
    "fig_height = 9.72441  # maxium height\n",
    "fontsize_title = 9 - 0\n",
    "fontsize_label = 8 - 0\n",
    "fontsize_legend = 8 - 0\n",
    "fontsize_axs = 8 - 0\n",
    "\n",
    "spineline_width = 0.3\n",
    "\n",
    "# sns.set_style('ticks')  # darkgrid, white grid, dark, white and ticks\n",
    "# plt.style.use('default')\n",
    "\n",
    "plt.rcParams[\"axes.spines.right\"] = False\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"axes.linewidth\"] = spineline_width\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"calibri\"  # \"times new roman\"\n",
    "plt.rcParams[\"legend.facecolor\"] = \"white\"\n",
    "plt.rcParams[\"legend.edgecolor\"] = \"black\"\n",
    "plt.rcParams[\"legend.shadow\"] = False\n",
    "plt.rcParams[\"legend.facecolor\"] = \"white\"\n",
    "plt.rcParams[\"legend.edgecolor\"] = \"black\"\n",
    "plt.rcParams[\"font.size\"] = fontsize_axs\n",
    "plt.rcParams[\"legend.fontsize\"] = fontsize_legend\n",
    "plt.rcParams[\"axes.labelsize\"] = fontsize_axs\n",
    "plt.rcParams[\"ytick.labelsize\"] = fontsize_axs\n",
    "plt.rcParams[\"xtick.labelsize\"] = fontsize_axs\n",
    "plt.rcParams[\"axes.labelpad\"] = 0.0\n",
    "plt.rcParams[\"axes.linewidth\"] = spineline_width\n",
    "plt.rcParams[\"axes.spines.bottom\"] = True\n",
    "plt.rcParams[\"axes.spines.left\"] = True\n",
    "plt.rcParams[\"axes.spines.right\"] = True\n",
    "plt.rcParams[\"axes.spines.top\"] = True\n",
    "plt.rcParams[\"axes.titlesize\"] = fontsize_label\n",
    "plt.rcParams[\"xtick.labelsize\"] = fontsize_label\n",
    "plt.rcParams[\"xtick.major.width\"] = spineline_width\n",
    "plt.rcParams[\"ytick.major.width\"] = spineline_width\n",
    "plt.rcParams[\"xtick.minor.width\"] = spineline_width\n",
    "plt.rcParams[\"ytick.minor.width\"] = spineline_width\n",
    "plt.rcParams[\"figure.titlesize\"] = fontsize_title\n",
    "plt.rcParams[\"grid.linewidth\"] = spineline_width\n",
    "plt.rcParams[\"axes.grid.axis\"] = \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementa LANCA land use method - erosion potential\n",
    "metadata = (\n",
    "    (\"LANCA v2.5 - land use\", \"erosion potential\"),\n",
    "    \"kg soil loss\",\n",
    "    \"LANCA v2.5 - Characterization Factors for Erosion Potential due to land occupation and transformation (to/from) \\\n",
    "            Available at: https://www.bookshop.fraunhofer.de/buch/LANCA/244600\",\n",
    "    Path(\"./data/Soil-Erosion-Potential_CFs_LANCA_v2.5.xlsx\"),\n",
    ")\n",
    "\n",
    "lanca_method = bw.ExcelLCIAImporter(\n",
    "    filepath=metadata[-1], name=metadata[0], unit=metadata[1], description=metadata[2]\n",
    ")\n",
    "lanca_method.apply_strategies()\n",
    "lanca_method.drop_unlinked()\n",
    "lanca_method.write_methods(overwrite=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCA methods\n",
    "lca_methods = [\n",
    "    met\n",
    "    for met in list(bw.methods)\n",
    "    if \"EF v3.1 no LT\" in met[0]\n",
    "    and (\n",
    "        \"acidification no LT\" == met[1]\n",
    "        or \"climate change no LT\" == met[1]\n",
    "        or \"ecotoxicity: freshwater no LT\" == met[1]\n",
    "        or \"energy resources: non-renewable no LT\" == met[1]\n",
    "        or \"eutrophication\" in met[1]\n",
    "        or \"human toxicity: carcinogenic no LT\" in met[1]\n",
    "        or \"human toxicity: non-carcinogenic no LT\" in met[1]\n",
    "        or \"ionising radiation: human health no LT\" in met[1]\n",
    "        or \"land use no LT\" == met[1]\n",
    "        or \"material resources: metals/minerals no LT\" in met[1]\n",
    "        or \"ozone depletion no LT\" in met[1]\n",
    "        or \"particulate matter formation no LT\" in met[1]\n",
    "        or \"photochemical\" in met[1]\n",
    "        or \"water use no LT\" in met[1]\n",
    "    )\n",
    "]\n",
    "lca_methods[1] = [\n",
    "    met\n",
    "    for met in list(bw.methods)\n",
    "    if \"climate change: including SLCFs\" in met[1]\n",
    "    and met[0] == \"IPCC 2021\"\n",
    "    and \"GWP100\" in met[2]\n",
    "][0]\n",
    "\n",
    "lca_methods.append([met for met in list(bw.methods) if \"LANCA\" in met[0]][0])\n",
    "lca_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality level of LCA methods\n",
    "quality_level = pd.Series(\n",
    "    {\n",
    "        \"Acidification\": \"II\",\n",
    "        \"Climate change\": \"I\",\n",
    "        \"Ecotoxicity freshwater\": \"II/III\",\n",
    "        \"Energy resources nonrenewable\": \"III\",\n",
    "        \"Eutrophication freshwater\": \"II\",\n",
    "        \"Eutrophication marine\": \"II\",\n",
    "        \"Eutrophication terrestrial\": \"II\",\n",
    "        \"Human toxicity carcinogenic\": \"II/III\",\n",
    "        \"Human toxicity noncarcinogenic\": \"II/III\",\n",
    "        \"Ionising radiation\": \"II\",\n",
    "        \"Land use\": \"III\",\n",
    "        \"Material resources metals minerals\": \"III\",\n",
    "        \"Ozone depletion\": \"I\",\n",
    "        \"Particulate matter formation\": \"I\",\n",
    "        \"Photochemical oxidant formation\": \"II\",\n",
    "        \"Water use\": \"III\",\n",
    "    },\n",
    "    name=\"Quality level\",\n",
    ")\n",
    "quality_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenarios' LCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenarios definition and LCIA calculation\n",
    "if DO_LCA or not os.path.isfile(LCA_PATH):\n",
    "    print(\"base\", \"--------------------\", sep=\"\\n\")\n",
    "    baseScenario = excel2ngScenarioLCA(\"base\", supply_scenario_y2021, ei_ng_db)\n",
    "    assert baseScenario.no_double_counting is True\n",
    "    baseScenario.doLCA(lca_methods)\n",
    "    print(\"Repower\", \"--------------------\", sep=\"\\n\")\n",
    "    repowerScenario = excel2ngScenarioLCA(\n",
    "        \"repower\", supply_scenario_alternative, ei_ng_db\n",
    "    )\n",
    "    assert repowerScenario.no_double_counting is True\n",
    "    repowerScenario.doLCA(lca_methods)\n",
    "    print(SCENARIOS[2], \"--------------------\", sep=\"\\n\")\n",
    "    y2022Scenario = excel2ngScenarioLCA(\"y2022\", supply_scenario_y2022, ei_ng_db)\n",
    "    y2022Scenario.NUCLEAR_POWER = max(y2022Scenario.NUCLEAR_POWER, 0.0)\n",
    "    y2022Scenario.HYDRO_POWER = max(y2022Scenario.HYDRO_POWER, 0.0)\n",
    "    assert y2022Scenario.no_double_counting is True\n",
    "    y2022Scenario.doLCA(lca_methods)\n",
    "    print(SCENARIOS[3], \"--------------------\", sep=\"\\n\")\n",
    "    coalScenario = excel2ngScenarioLCA(\"coal\", supply_scenario_alternative, ei_ng_db)\n",
    "    assert coalScenario.no_double_counting is True\n",
    "    coalScenario.doLCA(lca_methods)\n",
    "    print(SCENARIOS[4], \"--------------------\", sep=\"\\n\")\n",
    "    cleanScenario = excel2ngScenarioLCA(\"clean\", supply_scenario_alternative, ei_ng_db)\n",
    "    assert cleanScenario.no_double_counting is True\n",
    "    cleanScenario.doLCA(lca_methods)\n",
    "\n",
    "    lca_bkp = copy.deepcopy(\n",
    "        [baseScenario, repowerScenario, y2022Scenario, coalScenario, cleanScenario]\n",
    "    )\n",
    "    for sce in lca_bkp:\n",
    "        sce.lca_results = [\n",
    "            LCAResult(\n",
    "                demand=l_.demand,\n",
    "                method=l_.method,\n",
    "                score=l_.score,\n",
    "            )\n",
    "            for l_ in sce.lca_results\n",
    "        ]\n",
    "\n",
    "    with open(LCA_PATH, \"wb\") as fp:\n",
    "        pickle.dump(lca_bkp, fp)\n",
    "else:\n",
    "    with open(LCA_PATH, \"rb\") as fp:\n",
    "        lca_bkp = pickle.load(fp)\n",
    "    baseScenario = lca_bkp[0]\n",
    "    repowerScenario = lca_bkp[1]\n",
    "    y2022Scenario = lca_bkp[2]\n",
    "    coalScenario = lca_bkp[3]\n",
    "    cleanScenario = lca_bkp[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating/printing/saving dataframes\n",
    "baseScenario = copy.deepcopy(lca_bkp[0])\n",
    "repowerScenario = copy.deepcopy(lca_bkp[1])\n",
    "y2022Scenario = copy.deepcopy(lca_bkp[2])\n",
    "coalScenario = copy.deepcopy(lca_bkp[3])\n",
    "cleanScenario = copy.deepcopy(lca_bkp[4])\n",
    "\n",
    "i = [i for i, v in enumerate(baseScenario.categories) if \"land use no LT\" in v][0]\n",
    "\n",
    "list_of_NgScenarioLCA = [\n",
    "    baseScenario,\n",
    "    repowerScenario,\n",
    "    y2022Scenario,\n",
    "    coalScenario,\n",
    "    cleanScenario,\n",
    "]\n",
    "\n",
    "for scenario in list_of_NgScenarioLCA:\n",
    "    scenario.lca_results[i] = scenario.lca_results[-1]\n",
    "    scenario.lca_results = scenario.lca_results[:-1]\n",
    "    scenario.lca_methods.pop(-1)\n",
    "    scenario.categories.pop(-1)\n",
    "# baseScenario.categories\n",
    "\n",
    "df_results = result2df(list_of_NgScenarioLCA, verbose=False)\n",
    "\n",
    "# dataframe manipulation\n",
    "pd.options.display.float_format = \"{:0.2e}\".format\n",
    "df_results_lca_only = [df.iloc[:, 0] for df in df_results]\n",
    "df_results_lca_only = pd.concat(df_results_lca_only, axis=1)\n",
    "df_results_lca_only.sort_index(inplace=True)\n",
    "col = [col for col in df_results_lca_only.columns]\n",
    "for ite, colu in enumerate(df_results_lca_only.columns):\n",
    "    try:\n",
    "        col[ite] = (\n",
    "            colu.split(\" no LT \")[1]\n",
    "            .replace(\" human health\", \"\")\n",
    "            .replace(\":\", \"\")\n",
    "            .replace(\" \", \"_\")\n",
    "            .replace(\"-\", \"\")\n",
    "            .replace(\"/\", \"_\")\n",
    "            .capitalize()\n",
    "        )\n",
    "    except IndexError:\n",
    "        if \"land use\" in colu:\n",
    "            col[ite] = \"Land use\"\n",
    "        else:\n",
    "            col[ite] = \"Climate change\"\n",
    "\n",
    "col = [f\"{k.replace('_', ' ')} ({v})\" for k, v in zip(col, quality_level.values)]\n",
    "\n",
    "df_results_lca_only.columns = col\n",
    "df_results_lca_only.index = SCENARIOS\n",
    "\n",
    "if VERBOSE:\n",
    "    print(\"LCA results\")\n",
    "    ipd.display(df_results_lca_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanca_method = [met for met in list(bw.methods) if \"LANCA\" in met[0]][0]\n",
    "\n",
    "if DO_LCA or not os.path.exists(PATH2PICKLES + \"scenarios_lanca_only.pickle\"):\n",
    "    scenarios_lanca_only = [\n",
    "        excel2ngScenarioLCA(\"base\", supply_scenario_y2021, ei_ng_db),\n",
    "        excel2ngScenarioLCA(\"repower\", supply_scenario_alternative, ei_ng_db),\n",
    "        excel2ngScenarioLCA(\"y2022\", supply_scenario_y2022, ei_ng_db),\n",
    "        excel2ngScenarioLCA(\"coal\", supply_scenario_alternative, ei_ng_db),\n",
    "        excel2ngScenarioLCA(\"clean\", supply_scenario_alternative, ei_ng_db),\n",
    "    ]\n",
    "    scenarios_lanca_only[2].HYDRO_POWER = max(scenarios_lanca_only[2].HYDRO_POWER, 0.0)\n",
    "    scenarios_lanca_only[2].NUCLEAR_POWER = max(\n",
    "        scenarios_lanca_only[2].NUCLEAR_POWER, 0.0\n",
    "    )\n",
    "\n",
    "    [sce.doLCA([lanca_method]) for sce in scenarios_lanca_only]\n",
    "\n",
    "    for sce in scenarios_lanca_only:\n",
    "        sce.lca_results = [\n",
    "            LCAResult(\n",
    "                demand=l_.demand,\n",
    "                method=l_.method,\n",
    "                score=l_.score,\n",
    "            )\n",
    "            for l_ in sce.lca_results\n",
    "        ]\n",
    "\n",
    "    with open(PATH2PICKLES + \"scenarios_lanca_only.pickle\", \"wb\") as fp:\n",
    "        pickle.dump(scenarios_lanca_only, fp)\n",
    "else:\n",
    "    with open(PATH2PICKLES + \"scenarios_lanca_only.pickle\", \"rb\") as fp:\n",
    "        scenarios_lanca_only = pickle.load(fp)\n",
    "\n",
    "ipcc_methods = [\" \".join(met) for met in scenarios_lanca_only[0].lca_methods]\n",
    "dict_of_ipccs = {}\n",
    "\n",
    "for sce, sce_name in zip(scenarios_lanca_only, SCENARIOS):\n",
    "    dict_of_ipccs[sce_name] = sce.lca_results[0].score\n",
    "\n",
    "df_lanca_only = pd.DataFrame.from_dict(\n",
    "    dict_of_ipccs, orient=\"index\", columns=ipcc_methods\n",
    ")\n",
    "df_lanca_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcc_method = [\n",
    "    met\n",
    "    for met in list(bw.methods)\n",
    "    if met[0] == \"IPCC 2021\"\n",
    "    and \"climate change: including SLCFs\" in met[1]\n",
    "    and (\"GWP100\" in met[2] or \"GWP20\" in met[2])\n",
    "]\n",
    "\n",
    "IPCC_CO2_ONLY = (\"IPCC 2021\", \"Life cycle CO2 emissions\")\n",
    "try:\n",
    "    bw.Method(IPCC_CO2_ONLY).load()\n",
    "except:\n",
    "    gwp = bw.Method(ipcc_method[0]).load()\n",
    "    co2_cf = [\n",
    "        i\n",
    "        for i in gwp\n",
    "        if \"Carbon dioxide\" in bw.Database(\"biosphere3\").get(i[0][1])[\"name\"]\n",
    "    ]\n",
    "    metadata = {\"unit\": \"kg CO2\"}\n",
    "    co2_method = bw.Method((\"IPCC 2021\", \"Life cycle CO2 emissions\"))\n",
    "    co2_method.register(**metadata)\n",
    "    co2_method.write(co2_cf)\n",
    "    co2_method.process()\n",
    "\n",
    "if DO_LCA or not os.path.exists(PATH2PICKLES + \"scenarios_co2_only.pickle\"):\n",
    "    scenarios_co2_only = [\n",
    "        excel2ngScenarioLCA(\"base\", supply_scenario_y2021, ei_ng_db),\n",
    "        excel2ngScenarioLCA(\"repower\", supply_scenario_alternative, ei_ng_db),\n",
    "        excel2ngScenarioLCA(\"y2022\", supply_scenario_y2022, ei_ng_db),\n",
    "        excel2ngScenarioLCA(\"coal\", supply_scenario_alternative, ei_ng_db),\n",
    "        excel2ngScenarioLCA(\"clean\", supply_scenario_alternative, ei_ng_db),\n",
    "    ]\n",
    "    scenarios_co2_only[2].HYDRO_POWER = max(scenarios_co2_only[2].HYDRO_POWER, 0.0)\n",
    "    scenarios_co2_only[2].NUCLEAR_POWER = max(scenarios_co2_only[2].NUCLEAR_POWER, 0.0)\n",
    "\n",
    "    [sce.doLCA([IPCC_CO2_ONLY]) for sce in scenarios_co2_only]\n",
    "\n",
    "    for sce in scenarios_co2_only:\n",
    "        sce.lca_results = [\n",
    "            LCAResult(\n",
    "                demand=l_.demand,\n",
    "                method=l_.method,\n",
    "                score=l_.score,\n",
    "            )\n",
    "            for l_ in sce.lca_results\n",
    "        ]\n",
    "\n",
    "    with open(PATH2PICKLES + \"scenarios_co2_only.pickle\", \"wb\") as fp:\n",
    "        pickle.dump(scenarios_co2_only, fp)\n",
    "else:\n",
    "    with open(PATH2PICKLES + \"scenarios_co2_only.pickle\", \"rb\") as fp:\n",
    "        scenarios_co2_only = pickle.load(fp)\n",
    "\n",
    "ipcc_methods = [\" \".join(met) for met in scenarios_co2_only[0].lca_methods]\n",
    "dict_of_ipccs = {}\n",
    "\n",
    "for sce, sce_name in zip(scenarios_co2_only, SCENARIOS):\n",
    "    dict_of_ipccs[sce_name] = sce.lca_results[0].score\n",
    "\n",
    "df_co2_only = pd.DataFrame.from_dict(\n",
    "    dict_of_ipccs, orient=\"index\", columns=ipcc_methods\n",
    ")\n",
    "df_co2_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PB calculations\n",
    "def modify_pb_df(df):\n",
    "    df = df.copy()\n",
    "    df.sort_index(inplace=True)\n",
    "    df.index = df_results_lca_only.columns\n",
    "    df = df.T\n",
    "    return df\n",
    "\n",
    "\n",
    "# planetary boundaries data\n",
    "pb_percapta_dict = {\n",
    "    \"climate_change\": 501,  # 66.7% likelihood https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC_AR6_WGI_SPM_Stand_Alone.pdf\n",
    "    \"ozone_depletion\": 0.078,\n",
    "    \"eutrophication_marine\": 290,\n",
    "    \"eutrophication_freshwater\": 0.84,\n",
    "    \"eutrophication_terrestrial\": 887,\n",
    "    \"acidification\": 145,\n",
    "    \"land_use\": 1840,\n",
    "    \"water_use\": 26300,\n",
    "    \"particulate_matter\": 7.47e-5,\n",
    "    \"photochemical_ozone_formation\": 58.8,\n",
    "    \"human_toxicity_cancer\": 1.39e-4,\n",
    "    \"human_toxicity_noncancer\": 5.93e-4,\n",
    "    \"ecotoxicity_freshwater\": 1.9e4,\n",
    "    \"ionising_radiation\": 7.62e4,\n",
    "    \"energy_resources_nonrenewable\": 3.24e4,\n",
    "    \"material_resources_metals_minerals\": 3.18e-2,\n",
    "}  # https://doi.org/10.1016/j.jenvman.2020.110686\n",
    "\n",
    "EU_POPULATION = 447.0\n",
    "GLOBAL_POPULATION = 8000.0\n",
    "CUM_GLOBAL_POPULATION = 799_098_891_918  # from 2020-2100 https://www.sciencedirect.com/science/article/abs/pii/S0959378017312153?via%3Dihub\n",
    "\n",
    "pb_europe_dict = {}\n",
    "for k, v in pb_percapta_dict.items():\n",
    "    pb_europe_dict[k] = v * EU_POPULATION * 1e6\n",
    "\n",
    "df_pb_eu = pd.DataFrame.from_dict(pb_europe_dict, orient=\"index\", columns=[\"PB_EU\"])\n",
    "df_pb_percapita = pd.DataFrame.from_dict(\n",
    "    pb_percapta_dict, orient=\"index\", columns=[\"PB_percapita_yearly\"]\n",
    ")\n",
    "\n",
    "df_pb_eu = modify_pb_df(df_pb_eu)\n",
    "df_pb_percapita = modify_pb_df(df_pb_percapita)\n",
    "\n",
    "df_results_lca_only_ = df_results_lca_only.copy(deep=True)\n",
    "df_results_lca_only_.loc[:, \"Climate change (I)\"] = df_co2_only.values\n",
    "df_results_lca_only_.loc[:, \"Land use (III)\"] = df_lanca_only.values\n",
    "\n",
    "df_LCA_PB = pd.concat([df_results_lca_only_, df_pb_eu])\n",
    "\n",
    "df_ef_pb = pd.DataFrame()\n",
    "for col in df_LCA_PB.columns.to_list():\n",
    "    df_ef_pb[[col.replace(\"_\", \" \")]] = (\n",
    "        100 * df_LCA_PB[[col]].iloc[0 : len(SCENARIOS)] / df_LCA_PB[[col]].iloc[-1]\n",
    "    )\n",
    "df_ef_pb.set_axis(SCENARIOS)\n",
    "\n",
    "df_pb_unit = pd.DataFrame(\n",
    "    {\n",
    "        col: [bw.methods[res.method][\"unit\"]]\n",
    "        for col, res in zip(df_ef_pb.columns, baseScenario.lca_results)\n",
    "    },\n",
    "    index=[\"Unit\"],\n",
    ")\n",
    "\n",
    "print(\"Per capita yearly budget\", \"--------------------\", sep=\"\\n\")\n",
    "ipd.display(pd.concat([df_pb_percapita, df_pb_unit]))\n",
    "print(\"EU27 yearly budget\", \"--------------------\", sep=\"\\n\")\n",
    "ipd.display(pd.concat([df_pb_eu, df_pb_unit]))\n",
    "print(\"EU27 yearly transgression\", \"--------------------\", sep=\"\\n\")\n",
    "(df_ef_pb / 1).map(\"{:,.2f}%\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_relevant_cols = [\n",
    "    \"Acidification (II)\",\n",
    "    \"Climate change (I)\",\n",
    "    \"Energy resources nonrenewable (III)\",\n",
    "\n",
    "    \"Eutrophication freshwater (II)\",\n",
    "    \"Eutrophication marine (II)\",\n",
    "    \"Eutrophication terrestrial (II)\",\n",
    "\n",
    "    \"Ionising radiation (II)\",\n",
    "    \"Land use (III)\",\n",
    "    \"Ozone depletion (I)\",\n",
    "\n",
    "    \"Particulate matter formation (I)\",\n",
    "    \"Photochemical oxidant formation (II)\",\n",
    "    \"Water use (III)\",\n",
    "]\n",
    "\n",
    "stat_relevant_index = [df_ef_pb.columns.tolist().index(col) for col in stat_relevant_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo calculation\n",
    "all_methods = (\n",
    "    ipcc_method\n",
    "    + [IPCC_CO2_ONLY]\n",
    "    + [\n",
    "        met\n",
    "        for met in list(bw.methods)\n",
    "        if \"EF v3.1 no LT\" in met[0]\n",
    "        and (\n",
    "            \"acidification no LT\" == met[1]\n",
    "            or \"climate change no LT\" == met[1]\n",
    "            or \"ecotoxicity: freshwater no LT\" == met[1]\n",
    "            or \"energy resources: non-renewable no LT\" == met[1]\n",
    "            or \"eutrophication\" in met[1]\n",
    "            or \"human toxicity: carcinogenic no LT\" in met[1]\n",
    "            or \"human toxicity: non-carcinogenic no LT\" in met[1]\n",
    "            or \"ionising radiation: human health no LT\" in met[1]\n",
    "            or \"land use no LT\" == met[1]\n",
    "            or \"material resources: metals/minerals no LT\" in met[1]\n",
    "            or \"ozone depletion no LT\" in met[1]\n",
    "            or \"particulate matter formation no LT\" in met[1]\n",
    "            or \"photochemical\" in met[1]\n",
    "            or \"water use no LT\" in met[1]\n",
    "        )\n",
    "    ]\n",
    "    + [met for met in list(bw.methods) if \"LANCA\" in met[0]]\n",
    ")\n",
    "\n",
    "all_methods_names = [\" | \".join(met) for met in all_methods]\n",
    "\n",
    "dict_ipcc_methods = {\n",
    "    k: v\n",
    "    for k, v in zip(\n",
    "        all_methods_names,\n",
    "        all_methods,\n",
    "    )\n",
    "}\n",
    "\n",
    "if RUN_MC or not os.path.exists(MC_PATH):\n",
    "    baseScenario_mc = copy.deepcopy(lca_bkp[0])\n",
    "    repowerScenario_mc = copy.deepcopy(lca_bkp[1])\n",
    "    y2022Scenario_mc = copy.deepcopy(lca_bkp[2])\n",
    "    coalScenario_mc = copy.deepcopy(lca_bkp[3])\n",
    "    cleanScenario_mc = copy.deepcopy(lca_bkp[4])\n",
    "\n",
    "    list_of_NgScenarioLCA = [\n",
    "        baseScenario_mc,\n",
    "        repowerScenario_mc,\n",
    "        y2022Scenario_mc,\n",
    "        coalScenario_mc,\n",
    "        cleanScenario_mc,\n",
    "    ]\n",
    "\n",
    "    if len(SKIP_MC) > 0:\n",
    "        try:\n",
    "            with open(MC_PATH, \"rb\") as pf:\n",
    "                mc_lca = pickle.load(pf)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\n",
    "                \"No Monte Carlo results found. Please set RUN_MC to True.\"\n",
    "            )\n",
    "    else:\n",
    "        mc_lca = dict()\n",
    "    for sce_name, sce in zip(SCENARIOS, list_of_NgScenarioLCA):\n",
    "        if sce_name in SKIP_MC:\n",
    "            continue\n",
    "        print(f\"Running Monte Carlo for {sce_name}\")\n",
    "        mc_lca[sce_name] = sce.multi_lcia_MonteCarlo(\n",
    "            N_mc,\n",
    "            dict_ipcc_methods,\n",
    "            seed=42,\n",
    "        )\n",
    "else:\n",
    "    with open(MC_PATH, \"rb\") as pf:\n",
    "        mc_lca = pickle.load(pf)\n",
    "\n",
    "mc_lca_bkp = copy.deepcopy(mc_lca)\n",
    "\n",
    "df_mc_lca = dict()\n",
    "for j, sce_name in enumerate(mc_lca.keys()):\n",
    "    df_mc_lca[sce_name] = pd.DataFrame.from_dict(mc_lca[sce_name])\n",
    "    df_mc_lca[sce_name].columns = all_methods_names\n",
    "\n",
    "for sce in SCENARIOS:\n",
    "    print(sce)\n",
    "    ipd.display(df_mc_lca[sce])\n",
    "\n",
    "if RUN_MC or not os.path.exists(MC_PATH):\n",
    "    with open(MC_PATH, \"wb\") as fp:\n",
    "        pickle.dump(df_mc_lca, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all scenarios in one dataframe\n",
    "categories = [\" \" for _ in baseScenario.categories]\n",
    "for ite, cate in enumerate(baseScenario.categories):\n",
    "    try:\n",
    "        categories[ite] = (\n",
    "            cate.split(\" no LT \")[1]\n",
    "            .replace(\" human health\", \"\")\n",
    "            .replace(\":\", \"\")\n",
    "            .replace(\" \", \"_\")\n",
    "            .replace(\"-\", \"\")\n",
    "            .replace(\"/\", \"_\")\n",
    "        )\n",
    "    except IndexError:\n",
    "        categories[ite] = \"climate change\"\n",
    "\n",
    "categories = [\n",
    "    f\"{nm.split(': h')[0].replace('_',' ').capitalize()} ({ql})\\n[{u.replace('-Eq','-eq').replace(' eq.','-eq').replace('CO2','CO$_2$').replace('H+','H$^+$').replace('m3','m$^3$')}]\"\n",
    "    for nm, u, ql in zip(categories, baseScenario.categories_unit, quality_level.values)\n",
    "]\n",
    "xlabels = [\n",
    "    \" \".join(txt.split(\"_\")).replace(\"nonrenewable\", \"non-renewable\")\n",
    "    for txt in categories\n",
    "]\n",
    "\n",
    "selected_categories = [\n",
    "    col for col in df_mc_lca[SCENARIOS[0]].columns if col.startswith(\"EF v3.1\")\n",
    "]\n",
    "selected_categories[\n",
    "    selected_categories.index(\n",
    "        \"EF v3.1 no LT | climate change no LT | global warming potential (GWP100) no LT\"\n",
    "    )\n",
    "] = \"IPCC 2021 | climate change: including SLCFs | global warming potential (GWP100)\"\n",
    "\n",
    "selected_cat_PB = copy.deepcopy(selected_categories)\n",
    "selected_cat_PB[\n",
    "    selected_cat_PB.index(\"EF v3.1 no LT | land use no LT | soil quality index no LT\")\n",
    "] = \"LANCA v2.5 - land use | erosion potential\"\n",
    "selected_cat_PB[\n",
    "    selected_cat_PB.index(\n",
    "        \"IPCC 2021 | climate change: including SLCFs | global warming potential (GWP100)\"\n",
    "    )\n",
    "] = \"IPCC 2021 | Life cycle CO2 emissions\"\n",
    "\n",
    "lcia2category_map_pb = dict(zip(selected_cat_PB, df_results_lca_only.columns))\n",
    "lcia2category_map = dict(zip(selected_categories, df_results_lca_only.columns))\n",
    "\n",
    "df_box_plot = pd.concat({k: d for k, d in df_mc_lca.items()})\n",
    "\n",
    "df_box_plot = df_box_plot.reset_index()\n",
    "df_box_plot.drop(\"level_1\", axis=1, inplace=True)\n",
    "df_box_plot.rename(columns={\"level_0\": \"scenario\"}, inplace=True)\n",
    "\n",
    "df_box_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MC results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin MC results\n",
    "fig, ax = plt.subplots(\n",
    "    4,\n",
    "    4,\n",
    "    figsize=(fig_length[2], fig_length[2]),\n",
    "    sharey=True,\n",
    ")\n",
    "ax = ax.flatten()\n",
    "\n",
    "\n",
    "for i, col in enumerate(selected_categories):\n",
    "    ax[i].set_title(\n",
    "        xlabels[i],\n",
    "    )\n",
    "    q_quantile = 0.0\n",
    "    q_quantile = 0.02\n",
    "    q_low = df_box_plot[col].quantile(q_quantile)\n",
    "    q_hi = df_box_plot[col].quantile(1 - q_quantile)\n",
    "    df_box_plot_ = df_box_plot[(df_box_plot[col] < q_hi) & (df_box_plot[col] > q_low)]\n",
    "\n",
    "    sns.violinplot(\n",
    "        data=df_box_plot_,\n",
    "        x=col,\n",
    "        y=\"scenario\",\n",
    "        hue=\"scenario\",\n",
    "        palette=COLORS[: len(SCENARIOS)],\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.3,\n",
    "        inner=None,\n",
    "        ax=ax[i],\n",
    "        gap=0.0,\n",
    "        density_norm=\"count\",\n",
    "        saturation=0.5,\n",
    "        legend=True if i == 0 else False,\n",
    "    )\n",
    "    sns.boxplot(\n",
    "        data=df_box_plot_,\n",
    "        x=col,\n",
    "        y=\"scenario\",\n",
    "        hue=\"scenario\",\n",
    "        palette=COLORS[: len(SCENARIOS)],\n",
    "        boxprops={\"zorder\": 2},\n",
    "        ax=ax[i],\n",
    "        width=0.3,\n",
    "        linewidth=0.5,\n",
    "        linecolor=\"black\",\n",
    "        flierprops={\"marker\": \"x\", \"color\": \"red\"},\n",
    "        fliersize=0.8,\n",
    "        legend=False,\n",
    "    )\n",
    "\n",
    "    ax[i].xaxis.set_major_formatter(ScalarFormatter())\n",
    "    ax[i].xaxis.set_minor_locator(AutoMinorLocator(3))\n",
    "    ax[i].tick_params(which=\"minor\", length=2)\n",
    "    ax[i].tick_params(which=\"major\", length=4)\n",
    "\n",
    "    ax[i].set(xlabel=None)\n",
    "    ax[i].set(ylabel=None)\n",
    "    ax[i].tick_params(axis=\"y\", which=\"both\", length=0)\n",
    "\n",
    "    def format_xtick(x, pos):\n",
    "        return f\"{x:.0g}\" if abs(x) >= 1_000 else f\"{x:g}\"\n",
    "\n",
    "    ax[i].xaxis.set_major_formatter(ticker.FuncFormatter(format_xtick))\n",
    "\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "ax[0].get_legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(f\"./figs/mc_violin_{N_mc}_ite.svg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistical results from MC simulations\n",
    "if RUN_MC or not os.path.exists(MC_PATH_LCA_ONLY):\n",
    "    results_lca_dict = dict()\n",
    "\n",
    "    for sce_name, sce in zip(SCENARIOS, list_of_NgScenarioLCA):\n",
    "        sce.doLCA(list(dict_ipcc_methods.values()))\n",
    "        results_lca_dict[sce_name] = {\n",
    "            k: v.score / 1e12 for k, v in zip(all_methods_names, sce.lca_results)\n",
    "        }\n",
    "\n",
    "    with open(MC_PATH_LCA_ONLY, \"wb\") as fp:\n",
    "        pickle.dump(results_lca_dict, fp)\n",
    "else:\n",
    "    with open(MC_PATH_LCA_ONLY, \"rb\") as fp:\n",
    "        results_lca_dict = pickle.load(fp)\n",
    "\n",
    "df_results_lca_all = pd.DataFrame.from_dict(results_lca_dict).T\n",
    "\n",
    "dict_stats_mc = {}\n",
    "\n",
    "for j, (key, val) in enumerate(df_mc_lca.items()):\n",
    "    q_quantile = 0.01\n",
    "    val_no_outlier = {}\n",
    "    for col in val.columns:\n",
    "        q_low = val[col].quantile(q_quantile)\n",
    "        q_hi = val[col].quantile(1 - q_quantile)\n",
    "        val_no_outlier[col] = val[(val[col] <= q_hi) & (val[col] >= q_low)][col]\n",
    "\n",
    "    val = pd.DataFrame(val_no_outlier)\n",
    "\n",
    "    df_base_mc_results = val.describe().T\n",
    "    df_base_mc_results[[col.capitalize() for col in df_base_mc_results.columns]] = (\n",
    "        df_base_mc_results\n",
    "    )\n",
    "    df_base_mc_results[\"Baseline\"] = df_results_lca_all.loc[key] * 1e12\n",
    "\n",
    "    df_base_mc_results[\"Mean-Baseline diff. [%]\"] = (\n",
    "        100\n",
    "        * (df_base_mc_results[\"Baseline\"] - df_base_mc_results[\"Mean\"])\n",
    "        / df_base_mc_results[\"Baseline\"]\n",
    "    )\n",
    "\n",
    "    distance_from_mean = (df_base_mc_results[\"75%\"] - df_base_mc_results[\"25%\"]) / 2\n",
    "\n",
    "    df_base_mc_results[\"CV [%]\"] = 100 * distance_from_mean / df_base_mc_results[\"Mean\"]\n",
    "    df_base_mc_results[\"CV-Std [%]\"] = (\n",
    "        100 * df_base_mc_results[\"Std\"] / df_base_mc_results[\"Mean\"]\n",
    "    )\n",
    "    df_base_mc_results[\"QCD [%]\"] = (\n",
    "        100\n",
    "        * abs(df_base_mc_results[\"75%\"] - df_base_mc_results[\"25%\"])\n",
    "        / abs(df_base_mc_results[\"75%\"] + df_base_mc_results[\"25%\"])\n",
    "    )\n",
    "\n",
    "    df_base_mc_results[\"MAD [%]\"] = (\n",
    "        100 * scipy.stats.median_abs_deviation(df_mc_lca[key]) / df_mc_lca[key].mean()\n",
    "    )\n",
    "\n",
    "    df_base_mc_results = df_base_mc_results[\n",
    "        [\n",
    "            \"Baseline\",\n",
    "            \"Mean\",\n",
    "            \"Std\",\n",
    "            # \"Count\",\n",
    "            # \"CV [%]\",\n",
    "            # \"CV-Std [%]\",\n",
    "            \"QCD [%]\",\n",
    "            # \"MAD [%]\",\n",
    "            \"Min\",\n",
    "            \"25%\",\n",
    "            \"50%\",\n",
    "            \"75%\",\n",
    "            \"Max\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    dict_stats_mc[key] = df_base_mc_results\n",
    "\n",
    "    df_base_mc_results_fmt = df_base_mc_results.map(\"{:,.2e}\".format)\n",
    "    df_base_mc_results_fmt[\"QCD [%]\"] = pd.to_numeric(\n",
    "        df_base_mc_results_fmt[\"QCD [%]\"]\n",
    "    ).map(\"{:,.2f}\".format)\n",
    "\n",
    "    print(key + \":\")\n",
    "    ipd.display(\n",
    "        df_base_mc_results_fmt.loc[df_base_mc_results.sort_values(by=\"QCD [%]\").index]\n",
    "    )\n",
    "\n",
    "    if save_tables:\n",
    "        with pd.ExcelWriter(\n",
    "            \"./data/results/lca_MC_statistical_results.xlsx\",\n",
    "            engine=\"openpyxl\",\n",
    "            mode=\"w\" if j == 0 else \"a\",\n",
    "        ) as writer:\n",
    "            df_base_mc_results_fmt.to_excel(writer, sheet_name=f\"MC-{key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P(A > B) and z-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculations\n",
    "\n",
    "##### Paired t-test for identical means\n",
    "\n",
    "1. Calculate the difference between the paired observations: $d = x_1 - x_2$, where $x_1$ and $x_2$ are the paired observations.\n",
    "2. Calculate the mean of the differences: $\\bar{d} = \\frac{1}{n}\\sum_{i=1}^{n} d_i$, where $n$ is the number of paired observations.\n",
    "3. Calculate the standard deviation of the differences: $s_d = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n}(d_i - \\bar{d})^2}$.\n",
    "4. Calculate the standard error of the mean difference: $SE = \\frac{s_d}{\\sqrt{n}}$.\n",
    "5. Calculate the t-statistic: $t = \\frac{\\bar{d}}{SE}$.\n",
    "6. Determine the degrees of freedom: $df = n - 1$.\n",
    "7. Calculate the p-value using the t-distribution with the appropriate degrees of freedom.\n",
    "\n",
    "The p-value represents the probability of observing a t-statistic as extreme as the one calculated, assuming the null hypothesis is true (i.e., the means are equal). A small p-value indicates strong evidence against the null hypothesis, suggesting that the means are significantly different.\n",
    "\n",
    "##### Probability of superiority $P(A>B)$\n",
    "\n",
    "$$P(A>B) = \\sum_{i=1}^n\\frac{\\min\\{0,\\max\\{1,a_i-b_i\\}\\}}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dict = {}\n",
    "prob_numeric_dict = {}\n",
    "\n",
    "for col in df_mc_lca[SCENARIOS[0]].columns:\n",
    "    scenario_dict = {}\n",
    "    a = df_mc_lca[SCENARIOS[0]][col]\n",
    "\n",
    "    for sce in SCENARIOS:\n",
    "        if sce == SCENARIOS[0]:\n",
    "            continue\n",
    "        b = df_mc_lca[sce][col]\n",
    "        correlation, p_value = pearsonr(a, b)\n",
    "        t_test_rel = scipy.stats.ttest_rel(a, b)\n",
    "        z_test = round(t_test_rel.pvalue, 4)\n",
    "\n",
    "        scenario_dict[f\"P[Base > {sce}]\"] = (a > b).mean()\n",
    "        scenario_dict[f\"Base == {sce}?\"] = z_test\n",
    "\n",
    "    prob_numeric_dict[col] = scenario_dict\n",
    "\n",
    "df_prob_mc_numeric = pd.DataFrame.from_dict(prob_numeric_dict).T\n",
    "df_prob_mc_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation scatter plot\n",
    "fig, ax = plt.subplots(4, 4, figsize=(10, 10), dpi=300 if save_fig else 100)\n",
    "ax = ax.flatten()\n",
    "\n",
    "\n",
    "df_mc_lca_renamed = {\n",
    "    k: v.copy(deep=True)[selected_categories].rename(columns=lcia2category_map)\n",
    "    for k, v in df_mc_lca.items()\n",
    "}\n",
    "\n",
    "for i, col in enumerate(df_mc_lca_renamed[SCENARIOS[0]].columns):\n",
    "    # remove outliers before scatter plot\n",
    "    q_quantile = 0.01\n",
    "    q_low = df_mc_lca_renamed[SCENARIOS[0]][col].quantile(q_quantile)\n",
    "    q_hi = df_mc_lca_renamed[SCENARIOS[0]][col].quantile(1 - q_quantile)\n",
    "    df_mc_lca_tmp = df_mc_lca_renamed[SCENARIOS[0]][\n",
    "        (df_mc_lca_renamed[SCENARIOS[0]][col] < q_hi)\n",
    "        & (df_mc_lca_renamed[SCENARIOS[0]][col] > q_low)\n",
    "    ]\n",
    "    for j, sce_name in enumerate(SCENARIOS[1:]):\n",
    "        df_mc_lca_tmp2 = df_mc_lca_renamed[sce_name][\n",
    "            (df_mc_lca_renamed[SCENARIOS[0]][col] < q_hi)\n",
    "            & (df_mc_lca_renamed[SCENARIOS[0]][col] > q_low)\n",
    "        ]\n",
    "        ax[i].scatter(\n",
    "            df_mc_lca_tmp[col],\n",
    "            df_mc_lca_tmp2[col],\n",
    "            s=0.5,\n",
    "            alpha=0.5,\n",
    "            c=COLORS[j],\n",
    "            marker=\"o\",\n",
    "        )\n",
    "\n",
    "    t_test_rel = scipy.stats.ttest_rel(\n",
    "        df_mc_lca_renamed[SCENARIOS[0]][col], df_mc_lca_renamed[SCENARIOS[1]][col]\n",
    "    )\n",
    "    ax[i].annotate(\n",
    "        f\"Paired t-test = {t_test_rel.pvalue:.2f}\",\n",
    "        xy=(0.05, 0.95),\n",
    "        xycoords=\"axes fraction\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "        fontsize=8,\n",
    "    )\n",
    "\n",
    "    ax[i].set_title(col)\n",
    "\n",
    "    ax[i].set(xlabel=SCENARIOS[0], ylabel=SCENARIOS[1])\n",
    "\n",
    "    ax[i].tick_params(axis=\"y\", which=\"both\", length=0)\n",
    "    ax[i].tick_params(axis=\"x\", which=\"both\", length=0)\n",
    "    ax[i].xaxis.set_major_formatter(ScalarFormatter())\n",
    "    ax[i].yaxis.set_major_formatter(ScalarFormatter())\n",
    "\n",
    "    ax[i].xaxis.set_minor_locator(AutoMinorLocator(3))\n",
    "    ax[i].tick_params(which=\"minor\", length=2)\n",
    "    ax[i].tick_params(which=\"major\", length=4)\n",
    "\n",
    "    ax[i].yaxis.set_minor_locator(AutoMinorLocator(3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format statistical results\n",
    "# df_prob_mc = pd.DataFrame.from_dict(prob_dict)\n",
    "df_prob_mc_numeric_renamed = (\n",
    "    df_prob_mc_numeric.loc[selected_categories]\n",
    "    .rename(index=lcia2category_map)\n",
    "    .copy(deep=True)\n",
    ")\n",
    "\n",
    "df_prob_mc_numeric_fmt = df_prob_mc_numeric_renamed.copy(deep=True)\n",
    "\n",
    "for col in df_prob_mc_numeric_fmt.columns:\n",
    "    df_prob_mc_numeric_fmt[col] = (\n",
    "        df_prob_mc_numeric_fmt[col].apply(lambda x: round(x, 2)).map(\"{:,.2f}\".format)\n",
    "    )\n",
    "\n",
    "df_prob_mc_numeric_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check thatn probability numeric (apos relation based on fixed seed in MC) is close to theoretical one\n",
    "a = (\n",
    "    df_mc_lca_renamed[SCENARIOS[0]][\"Climate change (I)\"]\n",
    "    / df_pb_eu[\"Climate change (I)\"].iloc[0]\n",
    ")\n",
    "b = (\n",
    "    df_mc_lca_renamed[SCENARIOS[1]][\"Climate change (I)\"]\n",
    "    / df_pb_eu[\"Climate change (I)\"].iloc[0]\n",
    ")\n",
    "c = (\n",
    "    df_mc_lca_renamed[SCENARIOS[2]][\"Climate change (I)\"]\n",
    "    / df_pb_eu[\"Climate change (I)\"].iloc[0]\n",
    ")\n",
    "d = (\n",
    "    df_mc_lca_renamed[SCENARIOS[3]][\"Climate change (I)\"]\n",
    "    / df_pb_eu[\"Climate change (I)\"].iloc[0]\n",
    ")\n",
    "e = (\n",
    "    df_mc_lca_renamed[SCENARIOS[4]][\"Climate change (I)\"]\n",
    "    / df_pb_eu[\"Climate change (I)\"].iloc[0]\n",
    ")\n",
    "\n",
    "prob_numeric = [(a > b).mean(), (a > c).mean(), (a > d).mean(), (a > e).mean()]\n",
    "\n",
    "# Theoretical approach (considering normal distribution)\n",
    "prob = [\n",
    "    norm.cdf((a.mean() - b.mean()) / np.sqrt(a.std() ** 2 + b.std() ** 2)),\n",
    "    norm.cdf((a.mean() - c.mean()) / np.sqrt(a.std() ** 2 + c.std() ** 2)),\n",
    "    norm.cdf((a.mean() - d.mean()) / np.sqrt(a.std() ** 2 + d.std() ** 2)),\n",
    "    norm.cdf((a.mean() - e.mean()) / np.sqrt(a.std() ** 2 + d.std() ** 2)),\n",
    "]\n",
    "\n",
    "print(\n",
    "    \"Climate change (I)\\nP[base>REPower]\\tP[base>y2022]\\tP[base>Coal]\\tP[base>Clean]\",\n",
    "    prob_numeric,\n",
    "    prob,\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save statistical results in Excel file\n",
    "if save_tables:\n",
    "    with pd.ExcelWriter(\n",
    "        \"./data/results/lca_MC_statistical_results.xlsx\",\n",
    "        engine=\"openpyxl\",\n",
    "        mode=\"a\",\n",
    "        if_sheet_exists=\"replace\",\n",
    "    ) as writer:\n",
    "        df_prob_mc_numeric_fmt[\n",
    "            [\"P[Base > REPowerEU]\", \"P[Base > Coal]\", \"P[Base > Clean]\"]\n",
    "        ].to_excel(writer, sheet_name=\"probabilities-numeric\")\n",
    "        df_prob_mc_numeric_fmt[\n",
    "            [\"Base == REPowerEU?\", \"Base == Coal?\", \"Base == Clean?\"]\n",
    "        ].to_excel(writer, sheet_name=\"z-test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P(A > B) visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base - REPowerEU comparison\n",
    "def create_base_minus_scenario(scenario=SCENARIOS[1]):\n",
    "    base_minus_repower = (\n",
    "        100\n",
    "        * (df_mc_lca_renamed[scenario] - df_mc_lca_renamed[SCENARIOS[0]])\n",
    "        / df_mc_lca_renamed[SCENARIOS[0]].abs()\n",
    "    )\n",
    "    # base_minus_repower = df_mc_lca_renamed[\"base\"] - df_mc_lca_renamed[\"repower\"]\n",
    "\n",
    "    for col in base_minus_repower.columns:\n",
    "        base_minus_repower[f\"color_{col}\"] = -1\n",
    "        base_minus_repower.loc[base_minus_repower[col] > 0, f\"color_{col}\"] = 1\n",
    "\n",
    "    base_minus_repower[\"dummy_color\"] = 0\n",
    "\n",
    "    base_minus_repower.rename(\n",
    "        columns={\n",
    "            col: col.replace(\"_\", \" \")\n",
    "            .replace(\"color \", \"color_\")\n",
    "            .replace(\"dummy \", \"dummy_\")\n",
    "            for col in base_minus_repower.columns\n",
    "            # if not col.startswith(\"color\") and not col.startswith(\"dummy\")\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "    return base_minus_repower\n",
    "\n",
    "\n",
    "base_minus_repower = create_base_minus_scenario(SCENARIOS[1])\n",
    "base_minus_y2022 = create_base_minus_scenario(SCENARIOS[2])\n",
    "base_minus_repower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of Base - REPowerEU\n",
    "def plot_hist_base_minus_sce(\n",
    "    base_minus_repower, scenario=SCENARIOS[1], save_fig=save_fig\n",
    "):\n",
    "    fig, ax = plt.subplots(4, 4, figsize=(fig_length[2], fig_length[2]), dpi=300 if save_fig else 100)\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    ax_lt0_leg_handles = []\n",
    "    ax_gt0_leg_handles = []\n",
    "\n",
    "    for i, col in enumerate(map(lcia2category_map.get, selected_categories)):\n",
    "        ax[i].set_title(\n",
    "            xlabels[i].split(\"\\n[\")[0],\n",
    "            fontsize=7,\n",
    "        )\n",
    "\n",
    "        q_quantile = 0.02\n",
    "        q_low = base_minus_repower[col].quantile(q_quantile)\n",
    "        q_hi = base_minus_repower[col].quantile(1 - q_quantile)\n",
    "        df_A_B_final = base_minus_repower[\n",
    "            (base_minus_repower[col] < q_hi) & (base_minus_repower[col] > q_low)\n",
    "        ][[col, f\"color_{col}\", \"dummy_color\"]]\n",
    "\n",
    "        pallete = [\"#fc8d62\", \"#66c2a5\"]\n",
    "        pallete = [COLORS[SCENARIOS.index(scenario)], \"#66c2a5\"]\n",
    "        if df_A_B_final.loc[df_A_B_final[col] < 0].sort_values(\n",
    "            by=f\"color_{col}\", ascending=False\n",
    "        ).shape[0] > 0.05 * len(df_A_B_final):\n",
    "            ax_lt0 = sns.histplot(\n",
    "                data=df_A_B_final.loc[df_A_B_final[col] < 0].sort_values(\n",
    "                    by=f\"color_{col}\", ascending=False\n",
    "                ),\n",
    "                x=col,\n",
    "                stat=\"frequency\",\n",
    "                hue=f\"color_{col}\",\n",
    "                palette=[pallete[0]],\n",
    "                binwidth=abs(df_A_B_final[col].max() - df_A_B_final[col].min()) / 25,\n",
    "                fill=True,\n",
    "                alpha=1.0,\n",
    "                ax=ax[i],\n",
    "                linewidth=0.3,\n",
    "                edgecolor=\"white\",\n",
    "                label=\"less\",\n",
    "                legend=True,\n",
    "            )\n",
    "            ax_lt0_leg_handles.append(ax_lt0.get_legend().legend_handles)\n",
    "            ax_lt0.get_legend().remove()\n",
    "        else:\n",
    "            ax_lt0_leg_handles.append(None)\n",
    "\n",
    "        if df_A_B_final.loc[df_A_B_final[col] >= 0].sort_values(\n",
    "            by=f\"color_{col}\", ascending=True\n",
    "        ).shape[0] > 0.05 * len(df_A_B_final):\n",
    "            ax_gt0 = sns.histplot(\n",
    "                data=df_A_B_final.loc[df_A_B_final[col] >= 0].sort_values(\n",
    "                    by=f\"color_{col}\", ascending=True\n",
    "                ),\n",
    "                x=col,\n",
    "                stat=\"frequency\",\n",
    "                hue=f\"color_{col}\",\n",
    "                palette=reversed(pallete),\n",
    "                binwidth=abs(df_A_B_final[col].max() - df_A_B_final[col].min()) / 25,\n",
    "                fill=True,\n",
    "                alpha=1.0,\n",
    "                ax=ax[i],\n",
    "                linewidth=0.3,\n",
    "                edgecolor=\"white\",\n",
    "                label=\"more\",\n",
    "                legend=True,\n",
    "            )\n",
    "            ax_gt0_leg_handles.append(ax_gt0.get_legend().legend_handles)\n",
    "            ax_gt0.get_legend().remove()\n",
    "        else:\n",
    "            ax_gt0_leg_handles.append(None)\n",
    "\n",
    "        line_treshold = ax[i].axvline(\n",
    "            x=0.0,\n",
    "            ls=\"--\",\n",
    "            lw=0.7,\n",
    "            color=\"black\",\n",
    "            label=\"Threshold\" if j == 15 else None,\n",
    "            alpha=0.75,\n",
    "        )\n",
    "\n",
    "        line_mean = ax[i].axvline(\n",
    "            x=df_A_B_final[col].mean(),\n",
    "            ls=\"-.\",\n",
    "            lw=0.7,\n",
    "            color=\"magenta\",\n",
    "            label=\"Mean\" if j == 15 else None,\n",
    "            alpha=0.75,\n",
    "        )\n",
    "        # plot an x at the mean and y=0\n",
    "        ax[i].plot(\n",
    "            [df_A_B_final[col].mean()],\n",
    "            [0],\n",
    "            marker=\"x\",\n",
    "            markersize=4,\n",
    "            color=\"magenta\",\n",
    "            lw=0.7,\n",
    "            label=None,\n",
    "        )\n",
    "\n",
    "        p_A_minus_B = (\n",
    "            f\"{100*df_prob_mc_numeric_renamed.loc[col, f'P[Base > {scenario}]']:0.0f}\"\n",
    "        )\n",
    "        p_A_minus_B = f\"{100*(base_minus_repower[col]>0).sum()/base_minus_repower[col].notna().sum():0.0f}\"\n",
    "        p_A_equals_B = (\n",
    "            f\"{100*df_prob_mc_numeric_renamed.loc[col, f'Base == {scenario}?']:0.0f}\"\n",
    "        )\n",
    "\n",
    "        xaxis_len = abs(ax[i].get_xlim()[1] - ax[i].get_xlim()[0])\n",
    "        yaxis_len = abs(ax[i].get_ylim()[1] - ax[i].get_ylim()[0])\n",
    "\n",
    "        # extend 20% of y-axis upwards to make room for the annotation\n",
    "        ax[i].set_ylim(\n",
    "            ax[i].get_ylim()[0],\n",
    "            ax[i].get_ylim()[1] + 0.2 * abs(ax[i].get_ylim()[1] - ax[i].get_ylim()[0]),\n",
    "        )\n",
    "\n",
    "        # add a coloured box below x-axis above the x=0 line to indicate the probability of A>B (called burden shifting)\n",
    "        right_side_annotation = True\n",
    "        is_yellow = False\n",
    "        if (\n",
    "            df_prob_mc_numeric_renamed.loc[col, f\"P[Base > {scenario}]\"] <= 0.75\n",
    "            and df_prob_mc_numeric_renamed.loc[col, f\"P[Base > {scenario}]\"] >= 0.25\n",
    "        ):\n",
    "            # set x-axis to be centered at 0\n",
    "            ax[i].set_xlim(\n",
    "                -1 * max(abs(ax[i].get_xlim()[0]), abs(ax[i].get_xlim()[1])),\n",
    "                max(abs(ax[i].get_xlim()[0]), abs(ax[i].get_xlim()[1])),\n",
    "            )\n",
    "            is_yellow = True\n",
    "\n",
    "        box_width = 180.0\n",
    "        if df_prob_mc_numeric_renamed.loc[col, f\"Base == {scenario}?\"] > 0.05:\n",
    "            annotation_txt = ax[i].text(\n",
    "                0.0 + 0.0 * xaxis_len,  # x-coordinate of the text\n",
    "                ax[i].get_ylim()[1] - 0.075 * yaxis_len,  # y-coordinate of the text\n",
    "                \"Inconclusive\"\n",
    "                + \"\\np-value = \"\n",
    "                + f\"{df_prob_mc_numeric_renamed.loc[col, f'Base == {scenario}?']:0.2f}\",\n",
    "                ha=\"center\",  # horizontal alignment\n",
    "                va=\"top\",  # vertical alignment\n",
    "                fontfamily=\"calibri\",\n",
    "                fontsize=fontsize_axs - 2,\n",
    "                # transform=ax[i].transAxes,\n",
    "                wrap=True,\n",
    "                bbox=dict(\n",
    "                    facecolor=\"#ffeda0\",\n",
    "                    alpha=0.85,\n",
    "                    edgecolor=\"black\",\n",
    "                    linewidth=0.3,\n",
    "                    boxstyle=\"darrow,pad=0.3\",\n",
    "                ),\n",
    "            )\n",
    "            annotation_txt._get_wrap_line_width = lambda: 2 * box_width\n",
    "        else:\n",
    "            if df_prob_mc_numeric_renamed.loc[col, f\"P[Base > {scenario}]\"] < 0.75:\n",
    "                annotation_txt = ax[i].text(\n",
    "                    0.0 + 0.02 * xaxis_len,  # x-coordinate of the text\n",
    "                    ax[i].get_ylim()[1] - 0.075 * yaxis_len,  # y-coordinate of the text\n",
    "                    (\n",
    "                        f\"superiority\\nP = {100-100*df_prob_mc_numeric_renamed.loc[col, f'P[Base > {scenario}]']:0.0f}%   \"  # text to display\n",
    "                        if df_prob_mc_numeric_renamed.loc[col, f\"P[Base > {scenario}]\"]\n",
    "                        > 0.25\n",
    "                        else f\"Burden shifting\\nP = {100-100*df_prob_mc_numeric_renamed.loc[col, f'P[Base > {scenario}]']:0.0f}%   \"\n",
    "                    ),  # text to display\n",
    "                    ha=\"left\",  # horizontal alignment\n",
    "                    va=\"top\",  # vertical alignment\n",
    "                    fontfamily=\"calibri\",  # font family\n",
    "                    fontsize=fontsize_axs - 2,  # font size\n",
    "                    wrap=True,\n",
    "                    bbox=dict(\n",
    "                        facecolor=\"red\" if not is_yellow else \"#ffeda0\",\n",
    "                        edgecolor=\"black\",\n",
    "                        alpha=0.5 if not is_yellow else 0.85,\n",
    "                        linewidth=0.3,\n",
    "                        boxstyle=\"rarrow,pad=0.3\",\n",
    "                    ),\n",
    "                )\n",
    "                annotation_txt._get_wrap_line_width = lambda: box_width\n",
    "            if df_prob_mc_numeric_renamed.loc[col, f\"P[Base > {scenario}]\"] > 0.25:\n",
    "                annotation_txt = ax[i].text(\n",
    "                    0.0 - 0.02 * xaxis_len,  # x-coordinate of the text\n",
    "                    ax[i].get_ylim()[1] - 0.075 * yaxis_len,  # y-coordinate of the text\n",
    "                    (\n",
    "                        f\"Inconclusive\\nP = {100*df_prob_mc_numeric_renamed.loc[col, f'P[Base > {scenario}]']:0.0f}%\"  # text to display\n",
    "                        if df_prob_mc_numeric_renamed.loc[col, f\"P[Base > {scenario}]\"]\n",
    "                        < 0.75\n",
    "                        else f\"Reduction\\nP = {100*df_prob_mc_numeric_renamed.loc[col, f'P[Base > {scenario}]']:0.0f}%\"\n",
    "                    ),  # text to display\n",
    "                    ha=\"right\",  # horizontal alignment\n",
    "                    va=\"top\",  # vertical alignment\n",
    "                    fontfamily=\"calibri\",  # font family\n",
    "                    fontsize=fontsize_axs - 2,  # font size\n",
    "                    wrap=True,\n",
    "                    bbox=dict(\n",
    "                        facecolor=\"green\" if not is_yellow else \"#ffeda0\",\n",
    "                        edgecolor=\"black\",\n",
    "                        alpha=0.5 if not is_yellow else 0.85,\n",
    "                        linewidth=0.3,\n",
    "                        boxstyle=\"larrow,pad=0.3\",\n",
    "                    ),\n",
    "                )\n",
    "                right_side_annotation = False\n",
    "                annotation_txt._get_wrap_line_width = lambda: box_width\n",
    "\n",
    "            N_stars = np.floor(np.log10(abs(df_A_B_final[col].mean()))).astype(int) + 1\n",
    "            N_stars = 0\n",
    "            if abs(df_A_B_final[col].mean()) > 10:\n",
    "                N_stars = 1\n",
    "            if abs(df_A_B_final[col].mean()) > 25:\n",
    "                N_stars = 2\n",
    "            if abs(df_A_B_final[col].mean()) > 100:\n",
    "                N_stars = 3\n",
    "\n",
    "            if df_prob_mc_numeric_renamed.loc[col, f\"P[Base > {scenario}]\"] >= 0.75:\n",
    "                # draw yellow stars for ratings in terms of base_minus_repower mean values\n",
    "                rating_ax = ax[i].scatter(\n",
    "                    [\n",
    "                        ax[i].get_xlim()[0] + (ite / 10 + 0.125) * xaxis_len\n",
    "                        for ite in range(3)\n",
    "                    ],\n",
    "                    3 * [ax[i].get_ylim()[1] - 0.5 * yaxis_len],\n",
    "                    marker=r\"$\\star$\",\n",
    "                    s=50,\n",
    "                    c=[\"yellow\"] * N_stars + [\"white\"] * (3 - N_stars),\n",
    "                    edgecolor=\"black\",\n",
    "                    linewidth=0.3,\n",
    "                    zorder=9,\n",
    "                    label=\"Relative mean difference\" if j == 15 else None,\n",
    "                )\n",
    "                # write 10%, 25% and 100% below each star in the plot\n",
    "                [\n",
    "                    ax[i].text(\n",
    "                        ax[i].get_xlim()[0] + (ite / 10 + 0.125) * xaxis_len,\n",
    "                        ax[i].get_ylim()[1] - 0.5 * yaxis_len - 0.075 * yaxis_len,\n",
    "                        val,\n",
    "                        ha=\"center\",\n",
    "                        va=\"center\",\n",
    "                        fontfamily=\"calibri\",\n",
    "                        fontsize=fontsize_axs - 3,\n",
    "                    )\n",
    "                    for ite, val in enumerate([\" 10\", \" 25\", \"100\"])\n",
    "                ]\n",
    "                # write relative mean difference [%] on top of the stars\n",
    "                ax[i].text(\n",
    "                    ax[i].get_xlim()[0] + (0.175 + 0.15 / 2) * xaxis_len,\n",
    "                    ax[i].get_ylim()[1] - 0.485 * yaxis_len + 0.125 * yaxis_len,\n",
    "                    \"Relative mean\\ndifference [%]\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontfamily=\"calibri\",\n",
    "                    fontsize=fontsize_axs - 2,\n",
    "                )\n",
    "            elif df_prob_mc_numeric_renamed.loc[col, f\"P[Base > {scenario}]\"] <= 0.25:\n",
    "                # draw red stars for ratings in terms of base_minus_repower mean values\n",
    "                rating_ax = ax[i].scatter(\n",
    "                    [\n",
    "                        ax[i].get_xlim()[1] - ((ite) / 10 + 0.1) * xaxis_len\n",
    "                        for ite in range(3)\n",
    "                    ],\n",
    "                    3 * [ax[i].get_ylim()[1] - 0.5 * yaxis_len],\n",
    "                    marker=r\"$\\star$\",\n",
    "                    s=50,\n",
    "                    c=[\"white\"] * (3 - N_stars) + [\"yellow\"] * N_stars,\n",
    "                    edgecolor=\"black\",\n",
    "                    linewidth=0.3,\n",
    "                    zorder=9,\n",
    "                    label=\"Relative mean difference\" if j == 15 else None,\n",
    "                )\n",
    "\n",
    "                # write 10%, 25% and 100% below each star in the plot\n",
    "                [\n",
    "                    ax[i].text(\n",
    "                        ax[i].get_xlim()[1] - (ite / 10 + 0.1) * xaxis_len,\n",
    "                        ax[i].get_ylim()[1] - 0.5 * yaxis_len - 0.075 * yaxis_len,\n",
    "                        val,\n",
    "                        ha=\"center\",\n",
    "                        va=\"center\",\n",
    "                        fontfamily=\"calibri\",\n",
    "                        fontsize=fontsize_axs - 3,\n",
    "                    )\n",
    "                    for ite, val in enumerate(reversed([\" 10\", \" 25\", \"100\"]))\n",
    "                ]\n",
    "                # write relative mean difference [%] on top of the stars\n",
    "                ax[i].text(\n",
    "                    ax[i].get_xlim()[1] - 0.225 * xaxis_len,\n",
    "                    ax[i].get_ylim()[1] - 0.485 * yaxis_len + 0.125 * yaxis_len,\n",
    "                    \"Relative mean\\ndifference [%]\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontfamily=\"calibri\",\n",
    "                    fontsize=fontsize_axs - 2,\n",
    "                )\n",
    "\n",
    "        ax[i].set(xlabel=None)\n",
    "        # ax2.set_ylabel(None)\n",
    "        if not i % 4 == 0:\n",
    "            ax[i].set(ylabel=None)\n",
    "\n",
    "        ax[i].xaxis.set_major_formatter(\"{x:.0f}%\")\n",
    "        ax[i].xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "        ax[i].tick_params(which=\"minor\", length=2)\n",
    "        ax[i].tick_params(which=\"major\", length=3)\n",
    "\n",
    "        ax[i].yaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "\n",
    "        ax[i].annotate(\n",
    "            ascii_uppercase[i] + \")\",\n",
    "            xy=(-0.2, 1.15),\n",
    "            xycoords=\"axes fraction\",\n",
    "            xytext=(+0.5, -0.5),\n",
    "            textcoords=\"offset fontsize\",\n",
    "            fontsize=\"medium\",\n",
    "            verticalalignment=\"top\",\n",
    "            fontfamily=\"calibri\",\n",
    "            # bbox=dict(facecolor=\"0.7\", edgecolor=\"none\", pad=3.0),\n",
    "        )\n",
    "\n",
    "    fig.supxlabel(f\"Environmental impact change from Base to {scenario} [%]\", y=0.02)\n",
    "\n",
    "    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "    lt0_leg_handles = [x for x in ax_lt0_leg_handles if x is not None][0]\n",
    "    gt0_leg_handles = [x for x in ax_gt0_leg_handles if x is not None][0]\n",
    "    leg = fig.legend(\n",
    "        # ax[1].get_legend().legend_handles\n",
    "        lt0_leg_handles + gt0_leg_handles\n",
    "        # + ax2_tmp.get_legend().legend_handles\n",
    "        + [line_treshold, line_mean, rating_ax],\n",
    "        [\n",
    "            \"Impact reduction\",\n",
    "            \"Burden shifting\",\n",
    "            \"Threshold\",\n",
    "            \"Mean\",\n",
    "            \"Relative mean difference [%]\",\n",
    "        ],\n",
    "        ncol=5,\n",
    "        loc=\"lower center\",\n",
    "        borderaxespad=0,\n",
    "        frameon=True,\n",
    "    )\n",
    "    for axx in ax:\n",
    "        try:\n",
    "            axx.get_legend().remove()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    leg.get_frame().set_linewidth(0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(\n",
    "            f\"./figs/mc_hist_A-{''.join(scenario.split(' '))}_pct_{N_mc}_ite.svg\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "fig, ax = plot_hist_base_minus_sce(\n",
    "    base_minus_repower, scenario=SCENARIOS[1], save_fig=save_fig\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_hist_base_minus_sce(\n",
    "    base_minus_y2022, scenario=SCENARIOS[2], save_fig=save_fig\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value heatmap\n",
    "for sce in SCENARIOS[1:]:\n",
    "    df_prob_mc_numeric_renamed[f\"Base and {sce}\"] = df_prob_mc_numeric_renamed[\n",
    "        f\"Base == {sce}?\"\n",
    "    ]\n",
    "\n",
    "ax_heatmap = sns.heatmap(\n",
    "    df_prob_mc_numeric_renamed[[f\"Base and {sce}\" for sce in SCENARIOS[1:]]],\n",
    "    vmin=0.0,\n",
    "    vmax=1.0,\n",
    "    cmap=\"Blues\",\n",
    "    annot=True,\n",
    "    fmt=\".0%\",\n",
    "    linewidths=1.5,\n",
    "    linecolor=\"white\",\n",
    "    annot_kws={\"size\": 8},\n",
    "    cbar=True,\n",
    "    cbar_kws=dict(\n",
    "        ticks=[_ / 10 for _ in range(11)],\n",
    "    ),\n",
    ")\n",
    "ax_heatmap.collections[0].colorbar.set_ticklabels(\n",
    "    [f\"{abs(t) * 100:0.0f}%\" for t in [_ / 10 for _ in range(11)]]\n",
    ")\n",
    "ax_heatmap.xaxis.tick_top()\n",
    "ax_heatmap.xaxis.set_tick_params(labeltop=True, rotation=30)\n",
    "plt.setp(ax_heatmap.get_yticklabels(), ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax_heatmap.yaxis.set_tick_params(rotation=-0)\n",
    "plt.setp(ax_heatmap.get_xticklabels(), ha=\"left\", rotation_mode=\"anchor\")\n",
    "\n",
    "# plt.title(\"MC statistical results - p-value\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\n",
    "        f\"./figs/mc_statsNumeric_pvalue_heatmap_{N_mc}_ite.svg\", bbox_inches=\"tight\"\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of burden shifting heatmap\n",
    "df_prob_mc_numeric_renamed[\n",
    "    [\"P[REPowerEU > Base]\", \"P[Coal > Base]\", \"P[Clean > Base]\"]\n",
    "] = (\n",
    "    1\n",
    "    - df_prob_mc_numeric_renamed[\n",
    "        [\"P[Base > REPowerEU]\", \"P[Base > Coal]\", \"P[Base > Clean]\"]\n",
    "    ]\n",
    ")\n",
    "for sce in SCENARIOS[1:]:\n",
    "    df_prob_mc_numeric_renamed[f\"P[{sce} > Base]\"] = (\n",
    "        1 - df_prob_mc_numeric_renamed[f\"P[Base > {sce}]\"]\n",
    "    )\n",
    "\n",
    "ax_heatmap = sns.heatmap(\n",
    "    df_prob_mc_numeric_renamed[[f\"P[{sce} > Base]\" for sce in SCENARIOS[1:]]],\n",
    "    vmin=0.0,\n",
    "    vmax=1.0,\n",
    "    cmap=\"Greens\",\n",
    "    annot=True,\n",
    "    fmt=\".0%\",\n",
    "    linewidths=1.5,\n",
    "    linecolor=\"white\",\n",
    "    annot_kws={\"size\": 8},\n",
    "    cbar=True,\n",
    "    cbar_kws=dict(\n",
    "        ticks=[_ / 10 for _ in range(11)],\n",
    "    ),\n",
    ")\n",
    "ax_heatmap.collections[0].colorbar.set_ticklabels(\n",
    "    [f\"{abs(t) * 100:0.0f}%\" for t in [_ / 10 for _ in range(11)]]\n",
    ")\n",
    "ax_heatmap.xaxis.tick_top()\n",
    "ax_heatmap.xaxis.set_tick_params(labeltop=True, rotation=30)\n",
    "plt.setp(ax_heatmap.get_yticklabels(), ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax_heatmap.yaxis.set_tick_params(rotation=-0)\n",
    "plt.setp(ax_heatmap.get_xticklabels(), ha=\"left\", rotation_mode=\"anchor\")\n",
    "\n",
    "# plt.title(\"MC statistical results - Numeric\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(f\"./figs/mc_statsNumeric_heatmap_{N_mc}_ite.svg\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistically significant burden-shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chance of Base > REPowerEU for p-value<0.05\n",
    "significant_categories = (\n",
    "    df_prob_mc_numeric_renamed.iloc[:, 0]\n",
    "    .loc[df_prob_mc_numeric_renamed[\"P[Base > REPowerEU]\"] < 0.05]\n",
    "    .index.tolist()\n",
    ")\n",
    "\n",
    "quality_level_fmt = quality_level.rename(\n",
    "    index={k: f\"{k} ({v})\" for k, v in quality_level.items()}\n",
    ")\n",
    "\n",
    "# statistically significant results\n",
    "pb_base = df_ef_pb.loc[SCENARIOS[0]][significant_categories]\n",
    "pb_repower = df_ef_pb.loc[SCENARIOS[1]][significant_categories]\n",
    "bs_repower = pd.Series((pb_repower - pb_base) / pb_base, name=\"Burden shifting\")\n",
    "qcd_df = (\n",
    "    dict_stats_mc[SCENARIOS[0]][\"QCD [%]\"]\n",
    "    .drop(index=\"LANCA v2.5 - land use | erosion potential\")\n",
    "    .rename(index=lcia2category_map)\n",
    ")\n",
    "df_significant_results = pd.concat(\n",
    "    [\n",
    "        pb_base,\n",
    "        pb_repower,\n",
    "        100 * bs_repower,\n",
    "        qcd_df.loc[significant_categories],\n",
    "        quality_level_fmt.loc[significant_categories],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "print(\"Sort by PB allocation of Base scenario\")\n",
    "ipd.display(df_significant_results.sort_values(by=SCENARIOS[1], ascending=False))\n",
    "\n",
    "print(\"Sort by burden shifting\")\n",
    "df_significant_results.sort_values(by=\"Burden shifting\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistically insignificant results\n",
    "insignificant_categories = [\n",
    "    ind for ind in df_prob_mc_numeric_renamed.index if ind not in significant_categories\n",
    "]\n",
    "pb_base = df_ef_pb.loc[SCENARIOS[0]][insignificant_categories]\n",
    "pb_repower = df_ef_pb.loc[SCENARIOS[1]][insignificant_categories]\n",
    "bs_repower = pd.Series((pb_repower - pb_base) / pb_base, name=\"Burden shifting\")\n",
    "df_insignificant_results = pd.concat(\n",
    "    [\n",
    "        pb_base,\n",
    "        pb_repower,\n",
    "        100 * bs_repower,\n",
    "        qcd_df.loc[insignificant_categories],\n",
    "        quality_level_fmt.loc[insignificant_categories],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(\"Sort by PB allocation of Base scenario\")\n",
    "ipd.display(df_insignificant_results.sort_values(by=SCENARIOS[0], ascending=False))\n",
    "\n",
    "print(\"Sort by burden shifting\")\n",
    "df_insignificant_results.sort_values(by=\"Burden shifting\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chance of Base > REPowerEU for QCD < 20\n",
    "significant_categories_qcd20 = (\n",
    "    df_prob_mc_numeric_renamed[\"P[Base > REPowerEU]\"]\n",
    "    .loc[abs(qcd_df.loc[df_prob_mc_numeric_renamed.index]) < 20]\n",
    "    .index.tolist()\n",
    ")\n",
    "\n",
    "# statistically significant results\n",
    "pb_base = df_ef_pb.loc[SCENARIOS[0]][significant_categories_qcd20]\n",
    "pb_repower = df_ef_pb.loc[SCENARIOS[1]][significant_categories_qcd20]\n",
    "bs_repower = pd.Series((pb_repower - pb_base) / pb_base, name=\"Burden shifting\")\n",
    "df_significant_results = pd.concat(\n",
    "    [\n",
    "        pb_base,\n",
    "        pb_repower,\n",
    "        100 * bs_repower,\n",
    "        100\n",
    "        * df_prob_mc_numeric_renamed[\"Base == REPowerEU?\"].loc[\n",
    "            significant_categories_qcd20\n",
    "        ],\n",
    "        qcd_df.loc[significant_categories_qcd20],\n",
    "        quality_level_fmt.loc[significant_categories_qcd20],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(\"Sort by QCD\")\n",
    "ipd.display(df_significant_results.sort_values(by=\"QCD [%]\", ascending=True))\n",
    "\n",
    "print(\"Sort by PB allocation of REPowerEU scenario\")\n",
    "ipd.display(df_significant_results.sort_values(by=SCENARIOS[1], ascending=False))\n",
    "\n",
    "print(\"Sort by burden shifting\")\n",
    "df_significant_results.sort_values(by=\"Burden shifting\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistically insignificant results\n",
    "insignificant_categories_qcd20 = [\n",
    "    ind\n",
    "    for ind in df_prob_mc_numeric_renamed.index\n",
    "    if ind not in significant_categories_qcd20\n",
    "]\n",
    "pb_base = df_ef_pb.loc[SCENARIOS[0]][insignificant_categories_qcd20]\n",
    "pb_repower = df_ef_pb.loc[SCENARIOS[1]][insignificant_categories_qcd20]\n",
    "bs_repower = pd.Series((pb_repower - pb_base) / pb_base, name=\"Burden shifting\")\n",
    "df_insignificant_results = pd.concat(\n",
    "    [\n",
    "        pb_base,\n",
    "        pb_repower,\n",
    "        100 * bs_repower,\n",
    "        # 100 * df_prob_mc_numeric_renamed[\"P[Base > REPowerEU]\"].loc[insignificant_categories_qcd20],\n",
    "        100\n",
    "        * df_prob_mc_numeric_renamed[\"Base == REPowerEU?\"].loc[\n",
    "            insignificant_categories_qcd20\n",
    "        ],\n",
    "        qcd_df.loc[insignificant_categories_qcd20],\n",
    "        quality_level_fmt.loc[insignificant_categories_qcd20],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(\"Sort by PB allocation of Base scenario\")\n",
    "ipd.display(df_insignificant_results.sort_values(by=SCENARIOS[0], ascending=False))\n",
    "\n",
    "print(\"Sort by burden shifting\")\n",
    "df_insignificant_results.sort_values(by=\"Burden shifting\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of transgressing 10% of SOS\n",
    "fig, ax_heatmap = plt.subplots(figsize=(fig_length[1.5], fig_length[1.5]))\n",
    "\n",
    "\n",
    "p_transgress_pb_10pct = {}\n",
    "\n",
    "for sce, df in df_mc_lca_renamed.items():\n",
    "    p_transgress_pb_10pct[sce] = (df >= 0.05 * df_pb_eu.iloc[0]).sum() / df.shape[0]\n",
    "\n",
    "p_transgress_pb_10pct = pd.DataFrame(p_transgress_pb_10pct)\n",
    "\n",
    "significant_categories_qcd20_no_quality3 = [\n",
    "    cat for cat in p_transgress_pb_10pct.index.tolist()  # if not cat.endswith(\"III)\")\n",
    "]\n",
    "\n",
    "ax_heatmap = sns.heatmap(\n",
    "    p_transgress_pb_10pct.loc[significant_categories_qcd20_no_quality3],\n",
    "    vmin=0.0,\n",
    "    vmax=1.0,\n",
    "    cmap=\"Greens\",\n",
    "    annot=True,\n",
    "    fmt=\".0%\",\n",
    "    linewidths=1.5,\n",
    "    linecolor=\"white\",\n",
    "    annot_kws={\"size\": 8},\n",
    "    cbar=True,\n",
    "    cbar_kws=dict(\n",
    "        ticks=[_ / 10 for _ in range(11)],\n",
    "    ),\n",
    ")\n",
    "ax_heatmap.collections[0].colorbar.set_ticklabels(\n",
    "    [f\"{abs(t) * 100:0.0f}%\" for t in [_ / 10 for _ in range(11)]]\n",
    ")\n",
    "ax_heatmap.xaxis.tick_top()\n",
    "ax_heatmap.xaxis.set_tick_params(labeltop=True, rotation=30)\n",
    "plt.setp(ax_heatmap.get_yticklabels(), ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax_heatmap.yaxis.set_tick_params(rotation=-0)\n",
    "plt.setp(ax_heatmap.get_xticklabels(), ha=\"left\", rotation_mode=\"anchor\")\n",
    "\n",
    "plt.title(\n",
    "    \"Probability of transgressing 10% of the SOS downscaled to energy consumption in the EU\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\n",
    "        f\"./figs/bs_pb_transgress10_heatmap_{N_mc}_ite.svg\", bbox_inches=\"tight\"\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of transgressing 100% of SOS\n",
    "fig, ax_heatmap = plt.subplots(figsize=(fig_length[1.5], fig_length[1.5]))\n",
    "\n",
    "p_transgress_pb_10pct = {}\n",
    "\n",
    "for sce, df in df_mc_lca_renamed.items():\n",
    "    p_transgress_pb_10pct[sce] = (df >= 1.0 * df_pb_eu.iloc[0]).sum() / df.shape[0]\n",
    "\n",
    "p_transgress_pb_10pct = pd.DataFrame(p_transgress_pb_10pct)\n",
    "\n",
    "significant_categories_qcd20_no_quality3 = [\n",
    "    cat for cat in p_transgress_pb_10pct.index.tolist()  # if not cat.endswith(\"III)\")\n",
    "]\n",
    "\n",
    "ax_heatmap = sns.heatmap(\n",
    "    p_transgress_pb_10pct.loc[significant_categories_qcd20_no_quality3],\n",
    "    vmin=0.0,\n",
    "    vmax=1.0,\n",
    "    cmap=\"Greens\",\n",
    "    annot=True,\n",
    "    fmt=\".0%\",\n",
    "    linewidths=1.5,\n",
    "    linecolor=\"white\",\n",
    "    annot_kws={\"size\": 8},\n",
    "    cbar=True,\n",
    "    cbar_kws=dict(\n",
    "        ticks=[_ / 10 for _ in range(11)],\n",
    "    ),\n",
    ")\n",
    "ax_heatmap.collections[0].colorbar.set_ticklabels(\n",
    "    [f\"{abs(t) * 100:0.0f}%\" for t in [_ / 10 for _ in range(11)]]\n",
    ")\n",
    "ax_heatmap.xaxis.tick_top()\n",
    "ax_heatmap.xaxis.set_tick_params(labeltop=True, rotation=30)\n",
    "plt.setp(ax_heatmap.get_yticklabels(), ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax_heatmap.yaxis.set_tick_params(rotation=-0)\n",
    "plt.setp(ax_heatmap.get_xticklabels(), ha=\"left\", rotation_mode=\"anchor\")\n",
    "\n",
    "plt.title(\n",
    "    r\"Probability of transgressing the SOS downscaled to energy consumption in the EU\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\n",
    "        f\"./figs/bs_pb_transgress100_heatmap_{N_mc}_ite.svg\", bbox_inches=\"tight\"\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOS heatmap\n",
    "fig, ax_heatmap = plt.subplots(figsize=(fig_length[1.5], fig_length[1.5]))\n",
    "\n",
    "ax_heatmap = sns.heatmap(\n",
    "    df_ef_pb.T / 100,\n",
    "    vmin=0.0,\n",
    "    vmax=1.0,\n",
    "    cmap=\"Reds\",\n",
    "    annot=True,\n",
    "    fmt=\".0%\",\n",
    "    linewidths=1.5,\n",
    "    linecolor=\"white\",\n",
    "    annot_kws={\"size\": 8},\n",
    "    cbar=True,\n",
    "    cbar_kws=dict(\n",
    "        ticks=[_ / 10 for _ in range(11)],\n",
    "    ),\n",
    ")\n",
    "ax_heatmap.collections[0].colorbar.set_ticklabels(\n",
    "    [f\"{abs(t) * 100:0.0f}%\" for t in [_ / 10 for _ in range(11)]]\n",
    ")\n",
    "ax_heatmap.xaxis.tick_top()\n",
    "ax_heatmap.xaxis.set_tick_params(labeltop=True, rotation=30)\n",
    "plt.setp(ax_heatmap.get_yticklabels(), ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax_heatmap.yaxis.set_tick_params(rotation=-0)\n",
    "plt.setp(ax_heatmap.get_xticklabels(), ha=\"left\", rotation_mode=\"anchor\")\n",
    "\n",
    "plt.title(r\"Share of the SOS downscaled to energy consumption in the EU\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(f\"./figs/bs_pb_heatmap_{N_mc}_ite.svg\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do process contribution analysis\n",
    "if DO_PROC_CONTRIB or not os.path.isfile(PROC_CONTRIB_PATH):\n",
    "    baseScenario_proc_contrib = copy.deepcopy(lca_bkp[0])\n",
    "    repowerScenario_proc_contrib = copy.deepcopy(lca_bkp[1])\n",
    "    y2022Scenario_proc_contrib = copy.deepcopy(lca_bkp[2])\n",
    "    coalScenario_proc_contrib = copy.deepcopy(lca_bkp[3])\n",
    "    cleanScenario_proc_contrib = copy.deepcopy(lca_bkp[4])\n",
    "\n",
    "    lca_methods_bkp = copy.deepcopy(lca_methods)\n",
    "\n",
    "    baseScenario_proc_contrib.do_process_contribution(lca_methods, verbose=False)\n",
    "    repowerScenario_proc_contrib.do_process_contribution(lca_methods, verbose=False)\n",
    "    y2022Scenario_proc_contrib.do_process_contribution(lca_methods, verbose=False)\n",
    "    coalScenario_proc_contrib.do_process_contribution(lca_methods, verbose=False)\n",
    "    cleanScenario_proc_contrib.do_process_contribution(lca_methods, verbose=False)\n",
    "\n",
    "    proc_contrib_bkp = [\n",
    "        copy.deepcopy(baseScenario_proc_contrib),\n",
    "        copy.deepcopy(repowerScenario_proc_contrib),\n",
    "        copy.deepcopy(y2022Scenario_proc_contrib),\n",
    "        copy.deepcopy(coalScenario_proc_contrib),\n",
    "        copy.deepcopy(cleanScenario_proc_contrib),\n",
    "    ]\n",
    "\n",
    "    for sce in proc_contrib_bkp:\n",
    "        sce.lca_results = [\n",
    "            LCAResult(\n",
    "                demand=l_.demand,\n",
    "                method=l_.method,\n",
    "                score=l_.score,\n",
    "            )\n",
    "            for l_ in sce.lca_results\n",
    "        ]\n",
    "\n",
    "    with open(PROC_CONTRIB_PATH, \"wb\") as fp:\n",
    "        pickle.dump(proc_contrib_bkp, fp)\n",
    "else:\n",
    "    with open(PROC_CONTRIB_PATH, \"rb\") as fp:\n",
    "        proc_contrib_bkp = pickle.load(fp)\n",
    "    baseScenario_proc_contrib = copy.deepcopy(proc_contrib_bkp[0])\n",
    "    repowerScenario_proc_contrib = copy.deepcopy(proc_contrib_bkp[1])\n",
    "    y2022Scenario_proc_contrib = copy.deepcopy(proc_contrib_bkp[2])\n",
    "    coalScenario_proc_contrib = copy.deepcopy(proc_contrib_bkp[3])\n",
    "    cleanScenario_proc_contrib = copy.deepcopy(proc_contrib_bkp[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot product/source contribution simplified\n",
    "fig_proc_contrib, ax_proc_contrib = plot_proc_contrib(\n",
    "    [\n",
    "        baseScenario_proc_contrib,\n",
    "        repowerScenario_proc_contrib,\n",
    "        y2022Scenario_proc_contrib,\n",
    "        coalScenario_proc_contrib,\n",
    "        cleanScenario_proc_contrib,\n",
    "    ],\n",
    "    save_fig=save_fig,\n",
    "    path2save_fig=\"./figs/proc_contrib_NG_scenarios.png\",\n",
    "    quality_level=quality_level,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process contribution ranking\n",
    "cc_pc = list(baseScenario_proc_contrib.process_contribution.keys())\n",
    "cc_pc = [\n",
    "    v[\n",
    "        \"('IPCC 2021', 'climate change: including SLCFs', 'global warming potential (GWP100)')\"\n",
    "    ]\n",
    "    for k, v in baseScenario_proc_contrib.process_contribution.items()\n",
    "]\n",
    "cc_pc_pct = [c / sum(cc_pc) for c in cc_pc]\n",
    "cc_pc_pct_df = pd.DataFrame(\n",
    "    cc_pc_pct,\n",
    "    columns=[\"climate change base [%]\"],\n",
    "    index=[\n",
    "        k.split(\" - \")[0] for k in baseScenario_proc_contrib.process_contribution.keys()\n",
    "    ],\n",
    ")\n",
    "cc_pc_pct_df.sort_values(by=\"climate change base [%]\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot product/source contribution simplified\n",
    "fig_proc_contrib, ax_proc_contrib = plot_proc_contrib(\n",
    "    [\n",
    "        baseScenario_proc_contrib,\n",
    "        repowerScenario_proc_contrib,\n",
    "        y2022Scenario_proc_contrib,\n",
    "        # coalScenario_proc_contrib,\n",
    "        # cleanScenario_proc_contrib,\n",
    "    ],\n",
    "    save_fig=save_fig,\n",
    "    path2save_fig=\"./figs/proc_contrib_NG_scenarios_errorbar.png\",\n",
    "    quality_level=quality_level,\n",
    "    dict_stats_mc=dict_stats_mc,\n",
    "    stat_relevant_index=stat_relevant_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot product/source contribution simplified\n",
    "fig_proc_contrib, ax_proc_contrib = plot_proc_contrib(\n",
    "    [\n",
    "        baseScenario_proc_contrib,\n",
    "        repowerScenario_proc_contrib,\n",
    "        y2022Scenario_proc_contrib,\n",
    "        coalScenario_proc_contrib,\n",
    "        cleanScenario_proc_contrib,\n",
    "    ],\n",
    "    save_fig=save_fig,\n",
    "    path2save_fig=\"./figs/proc_contrib_NG_scenarios_errorbar_ESI.png\",\n",
    "    quality_level=quality_level,\n",
    "    dict_stats_mc=dict_stats_mc,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planetary boundaries based on EF 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_tables:\n",
    "    try:\n",
    "        (df_ef_pb / df_ef_pb.max()).to_excel(\"./data/results/ef_pb_results.xlsx\")\n",
    "    except PermissionError:\n",
    "        print(\"close excel to save a new one\")\n",
    "print(\"PB results\")\n",
    "(df_ef_pb / 1).map(\"{:,.2f}%\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories with >1% of the SOS\n",
    "for sce in SCENARIOS:\n",
    "    print(f\"Categories with > 10% of the SOS for {sce} scenario:\")\n",
    "    ipd.display(\n",
    "        df_ef_pb.loc[sce][df_ef_pb.loc[SCENARIOS[0]] > 10]\n",
    "        .sort_values(ascending=False)\n",
    "        .map(\"{:,.2f}%\".format)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box+violing PB log-scale unshared x-axis\n",
    "import math\n",
    "from string import ascii_uppercase\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    4,\n",
    "    math.ceil(len(stat_relevant_cols) / 4),\n",
    "    figsize=(fig_length[2], fig_length[2]),\n",
    "    sharey=True,\n",
    "    dpi=300 if save_fig else 100,\n",
    ")\n",
    "ax = ax.flatten()\n",
    "\n",
    "df_box_plot_pb = df_box_plot.copy(deep=True)\n",
    "df_box_plot_pb = df_box_plot_pb[selected_cat_PB + [\"scenario\"]].rename(\n",
    "    columns=lcia2category_map_pb\n",
    ")\n",
    "df_box_plot_pb = df_box_plot_pb.loc[df_box_plot_pb[\"scenario\"] != SCENARIOS[3]]\n",
    "df_box_plot_pb = df_box_plot_pb.loc[df_box_plot_pb[\"scenario\"] != SCENARIOS[4]]\n",
    "df_box_plot_pb[df_box_plot_pb.select_dtypes(float).columns] = (\n",
    "    df_box_plot_pb.select_dtypes(float).multiply(100)\n",
    ")\n",
    "\n",
    "for i, col in enumerate(stat_relevant_cols):\n",
    "    df_box_plot_pb[col] = df_box_plot_pb[col] / df_pb_eu[col].iloc[0]\n",
    "\n",
    "    ax[i].set_title(col)\n",
    "\n",
    "    q_quantile = 0.02\n",
    "    q_low = df_box_plot_pb[col].quantile(q_quantile)\n",
    "    q_hi = df_box_plot_pb[col].quantile(1 - q_quantile)\n",
    "    df_box_plot_pb = df_box_plot_pb[\n",
    "        (df_box_plot_pb[col] < q_hi) & (df_box_plot_pb[col] > q_low)\n",
    "    ]\n",
    "\n",
    "    sns.violinplot(\n",
    "        data=df_box_plot_pb,\n",
    "        x=col,\n",
    "        hue=\"scenario\",\n",
    "        y=\"scenario\",\n",
    "        palette=COLORS[: len(SCENARIOS)],\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.3,\n",
    "        inner=None,\n",
    "        ax=ax[i],\n",
    "        gap=0.0,\n",
    "        density_norm=\"count\",\n",
    "        saturation=0.5,\n",
    "        legend=True if i == 0 else False,\n",
    "        log_scale=True,  # if df_box_plot_pb[col].min() > 0 else False,\n",
    "        cut=0,\n",
    "    )\n",
    "    sns.boxplot(\n",
    "        data=df_box_plot_pb,\n",
    "        x=col,\n",
    "        hue=\"scenario\",\n",
    "        y=\"scenario\",\n",
    "        palette=COLORS[: len(SCENARIOS)],\n",
    "        boxprops={\"zorder\": 2},\n",
    "        ax=ax[i],\n",
    "        width=0.3,\n",
    "        linewidth=0.5,\n",
    "        linecolor=\"black\",\n",
    "        flierprops={\"marker\": \"x\", \"color\": \"red\"},\n",
    "        fliersize=0.0,\n",
    "        legend=False,\n",
    "        log_scale=True,  # if df_box_plot_pb[col].min() > 0 else False,\n",
    "    )\n",
    "\n",
    "    line = ax[i].axvline(\n",
    "        x=100.0,\n",
    "        ls=\"--\",\n",
    "        lw=0.75,\n",
    "        color=\"r\",\n",
    "        label=\"Earth's carrying capacity [%]\" if j == 0 else None,\n",
    "    )\n",
    "\n",
    "    ax[i].set(xlabel=None, ylabel=None)\n",
    "\n",
    "    lb = [1, 90, 1, 10, 0.1, 0.1, 0.1, 0.1, 0.1, 0.005, 0.1, 1.0, 0.1, 10, 1, 0.1]\n",
    "    lb = [lb[j] for j in stat_relevant_index]\n",
    "    ub = [110]*len(stat_relevant_index)\n",
    "    ub[1] = 1000\n",
    "    ub[2] = 1000\n",
    "    # ax[i].set_xlim([lb[i], ub[i]])\n",
    "    ax[i].set_xlim([lb[i], ax[i].get_xlim()[1]])\n",
    "\n",
    "    # ax[i].tick_params(axis=\"y\", which=\"both\", length=0)\n",
    "    ax[i].xaxis.set_major_formatter(ScalarFormatter())\n",
    "    if df_box_plot_pb[col].min() > 0:\n",
    "        ax[i].xaxis.set_major_locator(LogLocator(numticks=999))\n",
    "        ax[i].xaxis.set_minor_locator(LogLocator(numticks=999, subs=\"auto\"))\n",
    "        ax[i].tick_params(which=\"minor\", labelleft=False)\n",
    "\n",
    "    def format_xtick(x, pos):\n",
    "        return f\"{x:.0f}%\" if x >= 1 else f\"{x:g}%\"\n",
    "\n",
    "    ax[i].xaxis.set_major_formatter(ticker.FuncFormatter(format_xtick))\n",
    "    ax[i].xaxis.set_minor_formatter(ticker.FuncFormatter(lambda x, y: \"\"))\n",
    "\n",
    "\n",
    "fig.supxlabel(\"Share of Earth's carrying capacity [%]\", y=0.02)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "handles, labels = ax[0].get_legend_handles_labels()\n",
    "leg = fig.legend(\n",
    "    handles + [line],\n",
    "    SCENARIOS[:3] + [\"Earth's carrying capacity\"],\n",
    "    ncol=4,\n",
    "    loc=\"lower center\",\n",
    "    borderaxespad=0,\n",
    "    frameon=True,\n",
    ")\n",
    "ax[0].get_legend().remove()\n",
    "\n",
    "leg.get_frame().set_linewidth(0.3)\n",
    "\n",
    "plt.tick_params(axis=\"y\", length=0)\n",
    "\n",
    "for i, ax_ in enumerate(ax):\n",
    "    ax[i].annotate(\n",
    "        ascii_uppercase[i] + \")\",\n",
    "        xy=(-0.1, 1.15),\n",
    "        xycoords=\"axes fraction\",\n",
    "        xytext=(+0.5, -0.5),\n",
    "        textcoords=\"offset fontsize\",\n",
    "        fontsize=\"medium\",\n",
    "        verticalalignment=\"top\",\n",
    "        fontfamily=\"calibri\",\n",
    "        # bbox=dict(facecolor=\"0.7\", edgecolor=\"none\", pad=3.0),\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(f\"./figs/mc_box_violinplot_PB_log_{N_mc}_ite.svg\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box+violing PB log-scale unshared x-axis\n",
    "from string import ascii_uppercase\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    4,\n",
    "    4,\n",
    "    figsize=(fig_length[2], fig_length[2]),\n",
    "    sharey=True,\n",
    ")\n",
    "ax = ax.flatten()\n",
    "\n",
    "df_box_plot_pb = df_box_plot.copy(deep=True)\n",
    "df_box_plot_pb = df_box_plot_pb[selected_cat_PB + [\"scenario\"]].rename(\n",
    "    columns=lcia2category_map_pb\n",
    ")\n",
    "df_box_plot_pb[df_box_plot_pb.select_dtypes(float).columns] = (\n",
    "    df_box_plot_pb.select_dtypes(float).multiply(100)\n",
    ")\n",
    "\n",
    "for i, col in enumerate(df_pb_eu.columns):\n",
    "    df_box_plot_pb[col] = df_box_plot_pb[col] / df_pb_eu[col].iloc[0]\n",
    "\n",
    "    ax[i].set_title(\n",
    "        xlabels[i].split(\"\\n\")[0],\n",
    "    )\n",
    "\n",
    "    q_quantile = 0.02\n",
    "    q_low = df_box_plot_pb[col].quantile(q_quantile)\n",
    "    q_hi = df_box_plot_pb[col].quantile(1 - q_quantile)\n",
    "    df_box_plot_pb = df_box_plot_pb[\n",
    "        (df_box_plot_pb[col] < q_hi) & (df_box_plot_pb[col] > q_low)\n",
    "    ]\n",
    "\n",
    "    sns.violinplot(\n",
    "        data=df_box_plot_pb,\n",
    "        x=col,\n",
    "        hue=\"scenario\",\n",
    "        y=\"scenario\",\n",
    "        palette=COLORS[: len(SCENARIOS)],\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.3,\n",
    "        inner=None,\n",
    "        ax=ax[i],\n",
    "        gap=0.0,\n",
    "        density_norm=\"count\",\n",
    "        saturation=0.5,\n",
    "        legend=True if i == 0 else False,\n",
    "        log_scale=True,  # if df_box_plot_pb[col].min() > 0 else False,\n",
    "        cut=0,\n",
    "    )\n",
    "    sns.boxplot(\n",
    "        data=df_box_plot_pb,\n",
    "        x=col,\n",
    "        hue=\"scenario\",\n",
    "        y=\"scenario\",\n",
    "        palette=COLORS[: len(SCENARIOS)],\n",
    "        boxprops={\"zorder\": 2},\n",
    "        ax=ax[i],\n",
    "        width=0.3,\n",
    "        linewidth=0.5,\n",
    "        linecolor=\"black\",\n",
    "        flierprops={\"marker\": \"x\", \"color\": \"red\"},\n",
    "        fliersize=0.0,\n",
    "        legend=False,\n",
    "        log_scale=True,  # if df_box_plot_pb[col].min() > 0 else False,\n",
    "    )\n",
    "\n",
    "    line = ax[i].axvline(\n",
    "        x=100.0,\n",
    "        ls=\"--\",\n",
    "        lw=0.75,\n",
    "        color=\"r\",\n",
    "        label=\"Earth's carrying capacity [%]\" if j == 0 else None,\n",
    "    )\n",
    "\n",
    "    ax[i].set(xlabel=None, ylabel=None)\n",
    "\n",
    "    lb = [1, 90, 1, 10, 0.1, 0.1, 0.1, 0.1, 0.1, 0.005, 0.1, 1.0, 0.1, 10, 1, 0.1]\n",
    "    ax[i].set_xlim([lb[i], ax[i].get_xlim()[1]])\n",
    "\n",
    "    # ax[i].tick_params(axis=\"y\", which=\"both\", length=0)\n",
    "    ax[i].xaxis.set_major_formatter(ScalarFormatter())\n",
    "    if df_box_plot_pb[col].min() > 0:\n",
    "        ax[i].xaxis.set_major_locator(LogLocator(numticks=999))\n",
    "        ax[i].xaxis.set_minor_locator(LogLocator(numticks=999, subs=\"auto\"))\n",
    "        ax[i].tick_params(which=\"minor\", labelleft=False)\n",
    "\n",
    "    def format_xtick(x, pos):\n",
    "        return f\"{x:.0f}%\" if x >= 1 else f\"{x:g}%\"\n",
    "\n",
    "    ax[i].xaxis.set_major_formatter(ticker.FuncFormatter(format_xtick))\n",
    "    ax[i].xaxis.set_minor_formatter(ticker.FuncFormatter(lambda x, y: \"\"))\n",
    "\n",
    "\n",
    "fig.supxlabel(\"Share of Earth's carrying capacity [%]\", y=0.02)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "handles, labels = ax[0].get_legend_handles_labels()\n",
    "leg = fig.legend(\n",
    "    handles + [line],\n",
    "    SCENARIOS[:3] + [\"Earth's carrying capacity\"],\n",
    "    ncol=6,\n",
    "    loc=\"lower center\",\n",
    "    borderaxespad=0,\n",
    "    frameon=True,\n",
    ")\n",
    "ax[0].get_legend().remove()\n",
    "\n",
    "leg.get_frame().set_linewidth(0.3)\n",
    "\n",
    "plt.tick_params(axis=\"y\", length=0)\n",
    "\n",
    "for i, ax_ in enumerate(ax):\n",
    "    ax[i].annotate(\n",
    "        ascii_uppercase[i] + \")\",\n",
    "        xy=(-0.2, 1.05),\n",
    "        xycoords=\"axes fraction\",\n",
    "        xytext=(+0.5, -0.5),\n",
    "        textcoords=\"offset fontsize\",\n",
    "        fontsize=\"medium\",\n",
    "        verticalalignment=\"top\",\n",
    "        fontfamily=\"calibri\",\n",
    "        # bbox=dict(facecolor=\"0.7\", edgecolor=\"none\", pad=3.0),\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(f\"./figs/mc_box_violinplot_PB_log_ESI.svg\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations with `presamples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import presamples as ps\n",
    "\n",
    "\n",
    "ei_ng_db = bw.Database(DB_NAME)\n",
    "bio_db_bw = bw.Database(\"biosphere3\")\n",
    "\n",
    "\n",
    "def read_presamples_scenario_data(scenario_file, db_name):\n",
    "    \"\"\"\n",
    "    This function reads the scenario data from an excel file and prepares it into a dataframe for being used with Presamples.\n",
    "    Secondly, it adds the bw codes for the involved activities.\n",
    "    The dictionary map_bw_keys provides these codes, it needs to be generated beforehand with the involved databases.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create mapping of BW codes for involved databases\n",
    "    map_bw_keys = dict()\n",
    "    db = bw.Database(db_name)\n",
    "    for ds in db:\n",
    "        map_bw_keys[(ds[\"reference product\"], ds[\"name\"], ds[\"location\"])] = ds.key\n",
    "\n",
    "    scenario_df = pd.read_excel(scenario_file)  # Import data\n",
    "    scenario_df = scenario_df.dropna(how=\"any\")  # Delete empty rows\n",
    "\n",
    "    scenario_label = list(scenario_df.columns)[9:]  # Get label of scenarios\n",
    "\n",
    "    # add the bw code to your scenario DF (input = process, output = to_process)\n",
    "    scenario_df[\"input\"] = [\n",
    "        map_bw_keys[\n",
    "            (row[\"from_reference_product\"], row[\"from_process\"], row[\"from_location\"])\n",
    "        ]\n",
    "        for i, row in scenario_df.iterrows()\n",
    "    ]\n",
    "    scenario_df[\"output\"] = [\n",
    "        map_bw_keys[\n",
    "            (row[\"to_reference product\"], row[\"to_process\"], row[\"to_location\"])\n",
    "        ]\n",
    "        for i, row in scenario_df.iterrows()\n",
    "    ]\n",
    "    return scenario_label, scenario_df\n",
    "\n",
    "\n",
    "def make_pspackage(scenario_df, scenario_label, matrixlabel, ps_pkg_name):\n",
    "    \"\"\"\n",
    "    This function prepares a Presamples package out of the scenario data.\n",
    "    \"\"\"\n",
    "\n",
    "    # select needed data\n",
    "    samples = scenario_df[scenario_label].values\n",
    "    indices = [\n",
    "        (row[\"input\"], row[\"output\"], row[\"from_type\"])\n",
    "        for i, row in scenario_df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Generate PS data in PSpackage\n",
    "    data = [(samples, indices, matrixlabel)]\n",
    "\n",
    "    ps_id, ps_filepath = ps.create_presamples_package(\n",
    "        matrix_data=data, name=ps_pkg_name, seed=\"sequential\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n ps_id, filepath:\", ps_id, ps_filepath)\n",
    "\n",
    "    return samples, indices, ps_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCIA methods:\n",
    "LCIA_METHODS = {\n",
    "    \"Acidification (II)\": (\"EF v3.1\", \"acidification\", \"accumulated exceedance (AE)\"),\n",
    "    \"Climate change - CO2 (I)\": (\"IPCC 2021\", \"Life cycle CO2 emissions\"),\n",
    "    \"Climate change (I)\": (\n",
    "        \"IPCC 2021\",\n",
    "        \"climate change\",\n",
    "        \"global warming potential (GWP100)\",\n",
    "    ),\n",
    "    \"Ecotoxicity freshwater (II/III)\": (\n",
    "        \"EF v3.1\",\n",
    "        \"ecotoxicity: freshwater\",\n",
    "        \"comparative toxic unit for ecosystems (CTUe)\",\n",
    "    ),\n",
    "    \"Energy resources nonrenewable (III)\": (\n",
    "        \"EF v3.1\",\n",
    "        \"energy resources: non-renewable\",\n",
    "        \"abiotic depletion potential (ADP): fossil fuels\",\n",
    "    ),\n",
    "    \"Eutrophication freshwater (II)\": (\n",
    "        \"EF v3.1\",\n",
    "        \"eutrophication: freshwater\",\n",
    "        \"fraction of nutrients reaching freshwater end compartment (P)\",\n",
    "    ),\n",
    "    \"Eutrophication marine (II)\": (\n",
    "        \"EF v3.1\",\n",
    "        \"eutrophication: marine\",\n",
    "        \"fraction of nutrients reaching marine end compartment (N)\",\n",
    "    ),\n",
    "    \"Eutrophication terrestrial (II)\": (\n",
    "        \"EF v3.1\",\n",
    "        \"eutrophication: terrestrial\",\n",
    "        \"accumulated exceedance (AE)\",\n",
    "    ),\n",
    "    \"Human toxicity carcinogenic (II/III)\": (\n",
    "        \"EF v3.1\",\n",
    "        \"human toxicity: carcinogenic\",\n",
    "        \"comparative toxic unit for human (CTUh)\",\n",
    "    ),\n",
    "    \"Human toxicity noncarcinogenic (II/III)\": (\n",
    "        \"EF v3.1\",\n",
    "        \"human toxicity: non-carcinogenic\",\n",
    "        \"comparative toxic unit for human (CTUh)\",\n",
    "    ),\n",
    "    \"Ionising radiation (II)\": (\n",
    "        \"EF v3.1\",\n",
    "        \"ionising radiation: human health\",\n",
    "        \"human exposure efficiency relative to u235\",\n",
    "    ),\n",
    "    \"Land use (III)\": (\"EF v3.1\", \"land use\", \"soil quality index\"),\n",
    "    \"Land use - LANCA (III)\": (\"LANCA v2.5 - land use\", \"erosion potential\"),\n",
    "    \"Material resources metals minerals (III)\": (\n",
    "        \"EF v3.1\",\n",
    "        \"material resources: metals/minerals\",\n",
    "        \"abiotic depletion potential (ADP): elements (ultimate reserves)\",\n",
    "    ),\n",
    "    \"Ozone depletion (I)\": (\n",
    "        \"EF v3.1\",\n",
    "        \"ozone depletion\",\n",
    "        \"ozone depletion potential (ODP)\",\n",
    "    ),\n",
    "    \"Particulate matter formation (I)\": (\n",
    "        \"EF v3.1\",\n",
    "        \"particulate matter formation\",\n",
    "        \"impact on human health\",\n",
    "    ),\n",
    "    \"Photochemical oxidant formation (II)\": (\n",
    "        \"EF v3.1\",\n",
    "        \"photochemical oxidant formation: human health\",\n",
    "        \"tropospheric ozone concentration increase\",\n",
    "    ),\n",
    "    \"Water use (III)\": (\n",
    "        \"EF v3.1\",\n",
    "        \"water use\",\n",
    "        \"user deprivation potential (deprivation-weighted water consumption)\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "if not os.path.exists(PATH2RESULTS + \"sensitivity_analysis_results.csv\"):\n",
    "    # Read the excel file to get the scenario data\n",
    "    ps_data_path = \"./data/scenarios/presamples_sensitivity_analysis.xlsx\"\n",
    "\n",
    "    scenario_label, scenario_df = read_presamples_scenario_data(ps_data_path, DB_NAME)\n",
    "\n",
    "    # Create PS package with indices + samples matrix\n",
    "    samples_v1, indices_v1, ps_filepath_v1 = make_pspackage(\n",
    "        scenario_df, scenario_label, \"technosphere\", \"ps_v1\"\n",
    "    )\n",
    "\n",
    "    # Filter the activity in the database:\n",
    "    # activity_for_ps = [\n",
    "    #     ds for ds in bw.Database(DB_NAME) if \"energy from NG\" in ds[\"name\"]\n",
    "    # ][0]\n",
    "    activity_for_ps_lca = bw.LCA(\n",
    "        # demand={activity_for_ps: 1},\n",
    "        demand=baseScenario.functional_unit,\n",
    "        presamples=[ps_filepath_v1],\n",
    "        override_presamples_seed=True,\n",
    "    )\n",
    "\n",
    "    lcia_scenarios = dict()\n",
    "    for i in range(len(scenario_label)):  # Scenarios\n",
    "        if (\n",
    "            i == 0\n",
    "        ):  # Don't update the first time around, since indexer already at 0th column\n",
    "            activity_for_ps_lca.lci()  # Builds matrices\n",
    "            multi_lcia_results = dict()\n",
    "            for impact in LCIA_METHODS:\n",
    "                activity_for_ps_lca.switch_method(LCIA_METHODS[impact])\n",
    "                activity_for_ps_lca.lcia()\n",
    "                multi_lcia_results[impact] = activity_for_ps_lca.score\n",
    "        else:\n",
    "            activity_for_ps_lca.presamples.update_matrices()  # Move to next column and update matrices\n",
    "            activity_for_ps_lca.redo_lci()\n",
    "            multi_lcia_results = dict()\n",
    "            for impact in LCIA_METHODS:\n",
    "                activity_for_ps_lca.switch_method(LCIA_METHODS[impact])\n",
    "                activity_for_ps_lca.lcia()\n",
    "                multi_lcia_results[impact] = activity_for_ps_lca.score\n",
    "\n",
    "        lcia_scenarios[scenario_label[i]] = {**multi_lcia_results}\n",
    "\n",
    "    df_sens_analysis = pd.DataFrame(lcia_scenarios)\n",
    "    df_sens_analysis.to_csv(PATH2RESULTS + \"sensitivity_analysis_results.csv\")\n",
    "else:\n",
    "    df_sens_analysis = pd.read_csv(\n",
    "        PATH2RESULTS + \"sensitivity_analysis_results.csv\", index_col=0\n",
    "    )\n",
    "\n",
    "df_sens_analysis_pb = df_sens_analysis.copy(deep=True)\n",
    "df_sens_analysis_pb.drop([\"Climate change (I)\", \"Land use (III)\"], axis=0, inplace=True)\n",
    "df_sens_analysis_pb.rename(\n",
    "    index={\n",
    "        \"Climate change - CO2 (I)\": \"Climate change (I)\",\n",
    "        \"Land use - LANCA (III)\": \"Land use (III)\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "df_sens_analysis.drop(\n",
    "    [\"Climate change - CO2 (I)\", \"Land use - LANCA (III)\"], axis=0, inplace=True\n",
    ")\n",
    "\n",
    "df_sens_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "\n",
    "def heatmap_ng_lca(df_lca, save_fig=False, path2save=\"./figs/heatmap_ef\"):\n",
    "    plt.rcParams[\"font.size\"] = 6\n",
    "    plt.rcParams[\"axes.linewidth\"] = 0.3\n",
    "\n",
    "    fig = plt.figure(\n",
    "        constrained_layout=True,\n",
    "        figsize=(9.72441, 7.20472),\n",
    "        dpi=300 if save_fig else 120,\n",
    "    )\n",
    "    axm = fig.subplot_mosaic(\n",
    "        \"\"\"\n",
    "            dd\n",
    "            ss\n",
    "            qw\n",
    "        \"\"\",\n",
    "        gridspec_kw={\n",
    "            \"height_ratios\": [16, 2.0, 0.8],\n",
    "            \"wspace\": 0.02,\n",
    "            \"hspace\": 0.02,\n",
    "        },\n",
    "    )\n",
    "    axs = [axm[\"d\"], axm[\"s\"], axm[\"q\"], axm[\"w\"]]\n",
    "\n",
    "    valid_index = df_lca.index.to_list()\n",
    "    [valid_index.remove(key) for key in df_lca.index if key.startswith(\"$\\Delta\")]\n",
    "\n",
    "    sns.heatmap(\n",
    "        df_lca.loc[valid_index],\n",
    "        linewidth=1.5,\n",
    "        cmap=\"coolwarm\",\n",
    "        # center cmap in 0\n",
    "        center=0,\n",
    "        vmin=-0.005,  # max(df_lca.loc[valid_index].min().min(), -0.005),\n",
    "        vmax=0.005,  # min(df_lca.loc[valid_index].max().max() / 15, 0.005),\n",
    "        # vmax=0.05,\n",
    "        # vmin=min(df_lca.loc[valid_index].min().min(),-df_lca.loc[valid_index].max().max()),\n",
    "        # vmax=max(df_lca.loc[valid_index].max().max(), -df_lca.loc[valid_index].min().min()),\n",
    "        annot=True,\n",
    "        fmt=\"0.1%\",\n",
    "        annot_kws={\"size\": 7},\n",
    "        linewidths=1.5,\n",
    "        linecolor=\"white\",\n",
    "        ax=axs[0],\n",
    "        cbar=True,\n",
    "        cbar_ax=axs[2],  # orientation = 'horizontal'\n",
    "        cbar_kws=dict(orientation=\"horizontal\", shrink=1.0),\n",
    "    )\n",
    "\n",
    "    axs[0].set(\n",
    "        xlabel=\"\",\n",
    "        ylabel=\"\",\n",
    "        yticks=np.arange(0.5, len(valid_index) + 0.5, 1),\n",
    "        yticklabels=valid_index,\n",
    "    )\n",
    "    axs[0].set(xlabel=\"\", ylabel=\"\", xticklabels=df_lca.columns)\n",
    "    fmted_labels = [\n",
    "        \"\\n\".join(x.get_text().split(r\"\\n\")) for x in axs[0].get_yticklabels()\n",
    "    ]\n",
    "    axs[0].set_yticklabels(fmted_labels)\n",
    "    axs[0].xaxis.set_tick_params(labeltop=True, rotation=30)\n",
    "    axs[0].xaxis.tick_top()\n",
    "    plt.setp(axs[0].get_yticklabels(), ha=\"right\", rotation_mode=\"anchor\")\n",
    "    axs[0].yaxis.set_tick_params(rotation=-0)\n",
    "    plt.setp(axs[0].get_xticklabels(), ha=\"left\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # highlight categories in twin y axis [power plants, CHP, Industry, Househols]\n",
    "    # for i, cat in enumerate([\"Power plants\", \"CHP\", \"Industry\", \"Households\"]):\n",
    "    #     contains_cat = [cat in x for x in valid_index]\n",
    "    for ite, cat in zip(\n",
    "        [7, 10, 13, 15], [\"Power plants\", \"CHP\", \"Industry\", \"Households\"]\n",
    "    ):\n",
    "        axs[0].axhline(\n",
    "            y=ite - 0.05,\n",
    "            color=\"black\",\n",
    "            linewidth=1.0,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "        axs[0].annotate(\n",
    "            cat,\n",
    "            xy=(axs[0].get_xlim()[-1], ite - 0.05),\n",
    "            xytext=(axs[0].get_xlim()[-1], ite - 0.05),\n",
    "            textcoords=\"data\",\n",
    "            ha=\"left\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=7,\n",
    "        )\n",
    "\n",
    "    # New supply chain heatmap\n",
    "    delta_index = df_lca.index.str.startswith(r\"$\\Delta\")\n",
    "    df_delta_ng_comp = df_lca.loc[delta_index]\n",
    "\n",
    "    sns.heatmap(\n",
    "        df_delta_ng_comp,\n",
    "        linewidth=1.5,\n",
    "        # cmap=\"Greens\",  #'vlag',\n",
    "        cmap=sns.diverging_palette(145, 300, s=60, as_cmap=True),\n",
    "        # cmap=sns.diverging_palette(300, 145, s=60, as_cmap=True),\n",
    "        center=0,\n",
    "        vmin=-0.05,  # max(df_delta_ng_comp.min().min(), -0.05),\n",
    "        vmax=0.05,  # min(df_delta_ng_comp.max().max(), 0.05),\n",
    "        # vmin=min(df_delta_ng_comp.min().min(),-df_delta_ng_comp.max().max()),\n",
    "        # vmax=max(df_delta_ng_comp.max().max(), -df_delta_ng_comp.min().min()),\n",
    "        annot=True,\n",
    "        fmt=\"0.1%\",\n",
    "        annot_kws={\"size\": 7},\n",
    "        linewidths=1.5,\n",
    "        linecolor=\"white\",\n",
    "        ax=axs[1],\n",
    "        square=False,\n",
    "        # cbar=False,\n",
    "        cbar=True,\n",
    "        cbar_ax=axs[3],  # orientation = 'horizontal'\n",
    "        cbar_kws=dict(orientation=\"horizontal\", shrink=1.0),\n",
    "    )\n",
    "\n",
    "    axs[1].set(xlabel=\"\", ylabel=\"\", yticklabels=df_delta_ng_comp.index)\n",
    "    axs[1].yaxis.set_tick_params(labeltop=False, rotation=-0)\n",
    "    axs[1].xaxis.set_tick_params(\n",
    "        labeltop=False, labelbottom=False, bottom=False, rotation=-0\n",
    "    )\n",
    "\n",
    "    for spine in axs[2].spines.values():\n",
    "        spine.set(visible=True, lw=0.6, edgecolor=\"black\")\n",
    "    for spine in axs[3].spines.values():\n",
    "        spine.set(visible=True, lw=0.6, edgecolor=\"black\")\n",
    "\n",
    "    axs[2].set(\n",
    "        xlabel=\"Relative impact of each bcm switched\",\n",
    "        ylabel=\"\",\n",
    "    )\n",
    "    axs[3].set(xlabel=\"Relative impact of new NG supply chain\", ylabel=\"\")\n",
    "\n",
    "    for i in range(2, 4):\n",
    "        axs[i].tick_params(axis=\"x\", which=\"minor\", bottom=False)\n",
    "        axs[i].xaxis.set_major_formatter(\n",
    "            matplotlib.ticker.StrMethodFormatter(\"{x:.1%}\")\n",
    "        )\n",
    "\n",
    "    plt.rcParams.update(\n",
    "        {\n",
    "            \"figure.facecolor\": \"white\",  # (1.0, 1.0, 1.0, 1.0),  # red   with alpha = 30%\n",
    "            \"axes.facecolor\": \"white\",  # (1.0, 1.0, 1.0, 1.0),  # green with alpha = 50%\n",
    "            \"savefig.facecolor\": \"white\",  # (1.0, 1.0, 1.0, 1.0),  # blue  with alpha = 20%\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_facecolor((1.0, 1.0, 1.0, 1.0))\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(path2save + \".png\")\n",
    "        plt.savefig(path2save + \".svg\")\n",
    "\n",
    "    return fig, axs\n",
    "\n",
    "\n",
    "df_sens_analysis_pct = df_sens_analysis.drop(SCENARIOS[0], axis=1).T\n",
    "df_sens_analysis_base = df_sens_analysis[SCENARIOS[0]]\n",
    "df_sens_analysis_pct = (\n",
    "    df_sens_analysis_pct.sub(df_sens_analysis_base) / df_sens_analysis_base\n",
    ")\n",
    "\n",
    "fig_sensitivity, axs_sensitivity = heatmap_ng_lca(\n",
    "    df_sens_analysis_pct,\n",
    "    save_fig=save_fig,\n",
    ")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(f\"./figs/heatmap_ef.svg\")\n",
    "    plt.savefig(f\"./figs/heatmap_ef.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_ng_lca_pb(df_lca, df_pb, save_fig=False, path2save=\"./figs/heatmap_ef_pb\"):\n",
    "    plt.rcParams[\"font.size\"] = 6\n",
    "    plt.rcParams[\"axes.linewidth\"] = 0.3\n",
    "\n",
    "    fig = plt.figure(\n",
    "        constrained_layout=True,\n",
    "        figsize=(9.72441, 7.20472),\n",
    "        dpi=300 if save_fig else 120,\n",
    "    )\n",
    "    axm = fig.subplot_mosaic(\n",
    "        \"\"\"\n",
    "            ddd\n",
    "            sss\n",
    "            ppp\n",
    "            qwz\n",
    "        \"\"\",\n",
    "        gridspec_kw={\n",
    "            \"height_ratios\": [16, 2.0, 1.0, 0.8],\n",
    "            \"wspace\": 0.02,\n",
    "            \"hspace\": 0.02,\n",
    "        },\n",
    "    )\n",
    "    # axs = [axm[\"d\"], axm[\"s\"], axm[\"q\"], axm[\"w\"]]\n",
    "    axs = [ax for ax in axm.values()]\n",
    "\n",
    "    valid_index = df_lca.index.to_list()\n",
    "    [valid_index.remove(key) for key in df_lca.index if key.startswith(\"$\\Delta\")]\n",
    "\n",
    "    sns.heatmap(\n",
    "        df_lca.loc[valid_index],\n",
    "        linewidth=1.5,\n",
    "        cmap=\"coolwarm\",\n",
    "        # center cmap in 0\n",
    "        center=0,\n",
    "        vmin=-0.005,  # max(df_lca.loc[valid_index].min().min(), -0.005),\n",
    "        vmax=0.005,  # min(df_lca.loc[valid_index].max().max() / 15, 0.005),\n",
    "        # vmax=0.05,\n",
    "        # vmin=min(df_lca.loc[valid_index].min().min(),-df_lca.loc[valid_index].max().max()),\n",
    "        # vmax=max(df_lca.loc[valid_index].max().max(), -df_lca.loc[valid_index].min().min()),\n",
    "        annot=True,\n",
    "        fmt=\"0.1%\",\n",
    "        annot_kws={\"size\": 7},\n",
    "        linewidths=1.5,\n",
    "        linecolor=\"white\",\n",
    "        ax=axs[0],\n",
    "        cbar=True,\n",
    "        cbar_ax=axs[3],  # orientation = 'horizontal'\n",
    "        cbar_kws=dict(orientation=\"horizontal\", shrink=1.0),\n",
    "    )\n",
    "\n",
    "    axs[0].set(\n",
    "        xlabel=\"\",\n",
    "        ylabel=\"\",\n",
    "        yticks=np.arange(0.5, len(valid_index) + 0.5, 1),\n",
    "        yticklabels=valid_index,\n",
    "    )\n",
    "    axs[0].set(xlabel=\"\", ylabel=\"\", xticklabels=df_lca.columns)\n",
    "    fmted_labels = [\n",
    "        \"\\n\".join(x.get_text().split(r\"\\n\")) for x in axs[0].get_yticklabels()\n",
    "    ]\n",
    "    axs[0].set_yticklabels(fmted_labels)\n",
    "    axs[0].xaxis.set_tick_params(labeltop=True, rotation=30)\n",
    "    axs[0].xaxis.tick_top()\n",
    "    plt.setp(axs[0].get_yticklabels(), ha=\"right\", rotation_mode=\"anchor\")\n",
    "    axs[0].yaxis.set_tick_params(rotation=-0)\n",
    "    plt.setp(axs[0].get_xticklabels(), ha=\"left\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # highlight categories in twin y axis [power plants, CHP, Industry, Househols]\n",
    "    # for i, cat in enumerate([\"Power plants\", \"CHP\", \"Industry\", \"Households\"]):\n",
    "    #     contains_cat = [cat in x for x in valid_index]\n",
    "    for ite, cat in zip(\n",
    "        [7, 10, 13, 15], [\"Power plants\", \"CHP\", \"Industry\", \"Households\"]\n",
    "    ):\n",
    "        axs[0].axhline(\n",
    "            y=ite - 0.05,\n",
    "            color=\"black\",\n",
    "            linewidth=1.0,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "        axs[0].annotate(\n",
    "            cat,\n",
    "            xy=(axs[0].get_xlim()[-1], ite - 0.05),\n",
    "            xytext=(axs[0].get_xlim()[-1], ite - 0.05),\n",
    "            textcoords=\"data\",\n",
    "            ha=\"left\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=7,\n",
    "        )\n",
    "\n",
    "    # New supply chain heatmap\n",
    "    delta_index = df_lca.index.str.startswith(r\"$\\Delta\")\n",
    "    df_delta_ng_comp = df_lca.loc[delta_index]\n",
    "\n",
    "    sns.heatmap(\n",
    "        df_delta_ng_comp,\n",
    "        linewidth=1.5,\n",
    "        # cmap=\"Greens\",  #'vlag',\n",
    "        cmap=sns.diverging_palette(145, 300, s=60, as_cmap=True),\n",
    "        # cmap=sns.diverging_palette(300, 145, s=60, as_cmap=True),\n",
    "        center=0,\n",
    "        vmin=-0.01,  # max(df_delta_ng_comp.min().min(), -0.05),\n",
    "        vmax=0.01,  # min(df_delta_ng_comp.max().max(), 0.05),\n",
    "        # vmin=min(df_delta_ng_comp.min().min(),-df_delta_ng_comp.max().max()),\n",
    "        # vmax=max(df_delta_ng_comp.max().max(), -df_delta_ng_comp.min().min()),\n",
    "        annot=True,\n",
    "        fmt=\"0.1%\",\n",
    "        annot_kws={\"size\": 7},\n",
    "        linewidths=1.5,\n",
    "        linecolor=\"white\",\n",
    "        ax=axs[1],\n",
    "        square=False,\n",
    "        # cbar=False,\n",
    "        cbar=True,\n",
    "        cbar_ax=axs[4],  # orientation = 'horizontal'\n",
    "        cbar_kws=dict(orientation=\"horizontal\", shrink=1.0),\n",
    "    )\n",
    "\n",
    "    axs[1].set(xlabel=\"\", ylabel=\"\", yticklabels=df_delta_ng_comp.index)\n",
    "    axs[1].yaxis.set_tick_params(labeltop=False, rotation=-0)\n",
    "    axs[1].xaxis.set_tick_params(\n",
    "        labeltop=False, labelbottom=False, bottom=False, rotation=-0\n",
    "    )\n",
    "\n",
    "    sns.heatmap(\n",
    "        df_pb,\n",
    "        linewidth=1.5,\n",
    "        cmap=\"Blues\",  #'vlag',\n",
    "        # cmap=sns.diverging_palette(300, 145, s=60, as_cmap=True),\n",
    "        # center=0,\n",
    "        vmin=0.0,  # max(df_delta_ng_comp.min().min(), -0.05),\n",
    "        vmax=1.0,  # min(df_delta_ng_comp.max().max(), 0.05),\n",
    "        # vmin=min(df_delta_ng_comp.min().min(),-df_delta_ng_comp.max().max()),\n",
    "        # vmax=max(df_delta_ng_comp.max().max(), -df_delta_ng_comp.min().min()),\n",
    "        annot=True,\n",
    "        fmt=\"0.1%\",\n",
    "        annot_kws={\"size\": 7},\n",
    "        linewidths=1.5,\n",
    "        linecolor=\"white\",\n",
    "        ax=axs[2],\n",
    "        square=False,\n",
    "        cbar=True,\n",
    "        cbar_ax=axs[5],\n",
    "        cbar_kws=dict(orientation=\"horizontal\", shrink=1.0),\n",
    "    )\n",
    "\n",
    "    axs[2].set(xlabel=\"\", ylabel=\"\", yticklabels=[SCENARIOS[0]])\n",
    "    axs[2].yaxis.set_tick_params(labeltop=False, rotation=-0)\n",
    "    axs[2].xaxis.set_tick_params(\n",
    "        labeltop=False, labelbottom=False, bottom=False, rotation=-0\n",
    "    )\n",
    "\n",
    "    for i in range(3,6):\n",
    "        for spine in axs[i].spines.values():\n",
    "            spine.set(visible=True, lw=0.6, edgecolor=\"black\")\n",
    "\n",
    "    axs[3].set(xlabel=\"Relative impact of each bcm switched\", ylabel=\"\")\n",
    "    axs[4].set(xlabel=\"Relative impact of new NG supply chain\", ylabel=\"\")\n",
    "    axs[5].set(xlabel=f\"Transgression level of {SCENARIOS[0]}\", ylabel=\"\")\n",
    "\n",
    "    for i in range(2, 6):\n",
    "        axs[i].tick_params(axis=\"x\", which=\"minor\", bottom=False)\n",
    "        axs[i].xaxis.set_major_formatter(\n",
    "            matplotlib.ticker.StrMethodFormatter(\"{x:.1%}\")\n",
    "        )\n",
    "    axs[5].xaxis.set_major_formatter(\n",
    "        matplotlib.ticker.StrMethodFormatter(\"{x:.0%}\")\n",
    "    )\n",
    "\n",
    "    plt.rcParams.update(\n",
    "        {\n",
    "            \"figure.facecolor\": \"white\",  # (1.0, 1.0, 1.0, 1.0),  # red   with alpha = 30%\n",
    "            \"axes.facecolor\": \"white\",  # (1.0, 1.0, 1.0, 1.0),  # green with alpha = 50%\n",
    "            \"savefig.facecolor\": \"white\",  # (1.0, 1.0, 1.0, 1.0),  # blue  with alpha = 20%\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_facecolor((1.0, 1.0, 1.0, 1.0))\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(path2save + \".png\")\n",
    "        plt.savefig(path2save + \".svg\")\n",
    "\n",
    "    return fig, axs\n",
    "\n",
    "\n",
    "df_sens_analysis_pct_pb = df_sens_analysis_pb.drop(SCENARIOS[0], axis=1).T\n",
    "df_sens_analysis_base = df_sens_analysis_pb[SCENARIOS[0]]\n",
    "df_sens_analysis_pct_pb = df_sens_analysis_pct_pb.sub(df_sens_analysis_base)\n",
    "\n",
    "mult_val = 10\n",
    "multiplier_bcm = pd.Series(\n",
    "    [mult_val] * len(df_sens_analysis_pct_pb.index), index=df_sens_analysis_pct_pb.index\n",
    ")\n",
    "multiplier_bcm.loc[\"$\\Delta$NG REPowerEU\"] = 1\n",
    "multiplier_bcm.loc[\"$\\Delta$NG Year 2022\"] = 1\n",
    "\n",
    "# df_sens_analysis_pct_pb = df_sens_analysis_pct_pb * df_ef_pb.loc[].values / 100\n",
    "df_sens_analysis_pct_pb = (\n",
    "    df_sens_analysis_pct_pb / df_pb_eu.iloc[0, :]\n",
    ")  # * df_ef_pb.loc[].values / 100\n",
    "\n",
    "\n",
    "\n",
    "fig_sensitivity, axs_sensitivity = heatmap_ng_lca_pb(\n",
    "    # df_sens_analysis_pct_pb.multiply(multiplier_bcm, axis=0).loc[:, stat_relevant_cols],\n",
    "    # df_ef_pb.loc[[SCENARIOS[0]], stat_relevant_cols] / 100,\n",
    "    df_sens_analysis_pct_pb.multiply(multiplier_bcm, axis=0).loc[:, stat_relevant_cols],\n",
    "    df_ef_pb.loc[[SCENARIOS[0]], stat_relevant_cols] / 100,\n",
    "    save_fig=save_fig,\n",
    "    path2save=\"./figs/heatmap_ef_pb\",\n",
    ")\n",
    "\n",
    "axs_sensitivity[3].set(\n",
    "    xlabel=f\"EU's ecological limit impact per {mult_val} bcm switched\",\n",
    "    ylabel=\"\"\n",
    ")\n",
    "\n",
    "axs_sensitivity[4].set(\n",
    "    xlabel=\"EU's ecological limit impact of new NG supply chain\", ylabel=\"\"\n",
    ")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"./figs/heatmap_ef_pb.png\")\n",
    "    plt.savefig(\"./figs/heatmap_ef_pb.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick NG scenario LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCT change in impact\n",
    "alt_index = df_sens_analysis_pct.index.to_list()\n",
    "\n",
    "df_alternative = pd.Series([0.0] * len(alt_index), index=alt_index)\n",
    "\n",
    "df_alternative.loc[\"Nuclear power\"] = 7.0\n",
    "df_alternative.loc[\n",
    "    r\"Heat savings (mild winter,\\nefficiency improvements,\\nbehavior change)\"\n",
    "] = 10.0\n",
    "df_alternative.loc[\"Heat pumps (household)\"] = 9.0\n",
    "\n",
    "df_alternative_rep = df_alternative.copy(deep=True)\n",
    "\n",
    "df_alternative_rep.loc[\"Coal-fired power plants\"] = 24.0\n",
    "df_alternative.loc[\"Wind power\"] = 24.0\n",
    "\n",
    "assert df_alternative.sum() == 50.0\n",
    "assert df_alternative_rep.sum() == 50.0\n",
    "\n",
    "df_alternative = df_alternative * df_sens_analysis_pct.T\n",
    "df_alternative_rep = df_alternative_rep * df_sens_analysis_pct.T\n",
    "assert df_alternative.isna().sum().sum() == 0\n",
    "assert df_alternative_rep.isna().sum().sum() == 0\n",
    "\n",
    "solution = (\n",
    "    df_alternative.sum(axis=1) + df_sens_analysis_pct.loc[r\"$\\Delta$NG REPowerEU\"]\n",
    ") * 100\n",
    "solution_rep = (\n",
    "    df_alternative_rep.sum(axis=1) + df_sens_analysis_pct.loc[r\"$\\Delta$NG REPowerEU\"]\n",
    ") * 100\n",
    "\n",
    "final_alternative = pd.DataFrame(\n",
    "    [solution, solution_rep], index=[\"Alternative\", SCENARIOS[1]]\n",
    ").T\n",
    "final_alternative[\"Change\"] = (\n",
    "    final_alternative[\"Alternative\"] - final_alternative[SCENARIOS[1]]\n",
    ")\n",
    "final_alternative.sort_values(by=\"Change\", ascending=True).applymap(\n",
    "    lambda x: f\"{x:.1f}%\"\n",
    ")\n",
    "final_alternative.sort_values(by=\"Alternative\", ascending=True).applymap(\n",
    "    lambda x: f\"{x:.1f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_index = df_sens_analysis_pct_pb.index.to_list()\n",
    "\n",
    "df_alternative = pd.Series([0.0] * len(alt_index), index=alt_index)\n",
    "\n",
    "df_alternative.loc[\"Nuclear power\"] = 7.0\n",
    "df_alternative.loc[\"Coal-fired power plants\"] = 24.0\n",
    "df_alternative.loc[\n",
    "    r\"Heat savings (mild winter,\\nefficiency improvements,\\nbehavior change)\"\n",
    "] = 10.0\n",
    "df_alternative.loc[\"Heat pumps (household)\"] = 9.0\n",
    "\n",
    "assert df_alternative.sum() == 50.0\n",
    "\n",
    "df_alternative = df_alternative * df_sens_analysis_pct_pb.T\n",
    "assert df_alternative.isna().sum().sum() == 0\n",
    "\n",
    "solution = (\n",
    "    df_alternative.sum(axis=1) + df_sens_analysis_pct_pb.loc[r\"$\\Delta$NG REPowerEU\"]\n",
    ")\n",
    "solution = solution * 100 + df_ef_pb.loc[SCENARIOS[0]]\n",
    "\n",
    "solution.clip(lower=0).mean(), solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_index = df_sens_analysis_pct_pb.index.to_list()\n",
    "\n",
    "df_alternative = pd.Series([0.0] * len(alt_index), index=alt_index)\n",
    "\n",
    "df_alternative.loc[\"Nuclear power\"] = 0.0\n",
    "df_alternative.loc[\"Wind power\"] = 40.0\n",
    "df_alternative.loc[\n",
    "    r\"Heat savings (mild winter,\\nefficiency improvements,\\nbehavior change)\"\n",
    "] = 10.0\n",
    "df_alternative.loc[\"Heat pumps (household)\"] = 0.0\n",
    "\n",
    "assert df_alternative.sum() == 50.0\n",
    "\n",
    "df_alternative = df_alternative * df_sens_analysis_pct_pb.T\n",
    "assert df_alternative.isna().sum().sum() == 0\n",
    "\n",
    "solution = (\n",
    "    df_alternative.sum(axis=1) + df_sens_analysis_pct_pb.loc[r\"$\\Delta$NG REPowerEU\"]\n",
    ")\n",
    "solution = solution * 100 + df_ef_pb.loc[SCENARIOS[0]]\n",
    "\n",
    "solution.clip(lower=0).mean(), solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized array of measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization model\n",
    "\n",
    "\\begin{split}\n",
    "    \\min        & \\ \\ \\ \\sum_\\ell {\\mathbf{e}_\\ell}\\\\\n",
    "    \\text{s.t.} & \\ \\ \\ \\mathbf{t}_\\ell=\\sum_{r\\in R} \\left( \\mathbf{d}_r\\cdot\\mathbf{\\rho}_{r,\\ell} \\right) +\\mathbf{\\Delta}_\\ell ,   \\forall \\ell\\in L\\\\\n",
    "                & \\ \\ \\ \\mathbf{e}_\\ell\\ge \\mathbf{t}_\\ell,   \\forall \\ell\\in L\\\\\n",
    "                & \\ \\ \\ \\mathbf{e}_\\ell\\ge 0,   \\forall \\ell\\in L\\\\\n",
    "                & \\ \\ \\ \\sum_{r\\in R}{\\mathbf{d}_r} = \\bar{d}\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyomo.environ import *\n",
    "\n",
    "\n",
    "def instantiating_model(\n",
    "    df_pct,\n",
    "    demand_reduction=50,\n",
    "    constrain_savings=True,\n",
    "    obj_aggregator=sum,\n",
    "    pb_base=None,\n",
    "    limit_each_to=None,\n",
    "    demand_reduction_equals=True,\n",
    "):\n",
    "    print(f\"Demand reduction {demand_reduction}\")\n",
    "    model = ConcreteModel()\n",
    "\n",
    "    # Define the set of activities\n",
    "    valid_measures = [ind for ind in alt_index if not ind.startswith(r\"$\\Delta\")]\n",
    "    model.activities = Set(initialize=valid_measures)\n",
    "\n",
    "    # # Define the set of scenarios\n",
    "    lca_index_map = {col: i for i, col in enumerate(df_pct.columns)}\n",
    "    model.lca = Set(initialize=df_pct.columns)\n",
    "    M = 10_000\n",
    "\n",
    "    # Define the decision variables\n",
    "    model.decision = Var(model.activities, domain=NonNegativeReals)\n",
    "    model.impact = Var(model.lca, domain=NonNegativeReals)\n",
    "    model.slack_impact = Var(model.lca, domain=Reals)\n",
    "    # model.y_impact = Var(model.lca, domain=Binary)\n",
    "\n",
    "    # Define the objective function\n",
    "    def obj(m):\n",
    "        return summation(m.impact) / len(df_pct.columns)\n",
    "\n",
    "    # model.objective = Objective(expr=obj_aggregator(model.impact), sense=minimize)\n",
    "    model.objective = Objective(rule=obj, sense=minimize)\n",
    "\n",
    "    def transgression_calculation(m, l):\n",
    "        aux = (\n",
    "            sum([m.decision[act] * df_pct.loc[act, l] for act in m.activities])\n",
    "            + df_pct.loc[r\"$\\Delta$NG Year 2022\"].values.tolist()[lca_index_map[l]]\n",
    "        )\n",
    "        if pb_base is not None:\n",
    "            aux = 100 * (aux + pb_base[lca_index_map[l]])\n",
    "\n",
    "        return aux\n",
    "\n",
    "    model.slack_impact_def = Constraint(\n",
    "        model.lca,\n",
    "        expr=lambda m, l: m.slack_impact[l] == transgression_calculation(m, l),\n",
    "    )\n",
    "    model.slack_impact_constraint = Constraint(\n",
    "        model.lca, expr=lambda m, l: m.impact[l] >= m.slack_impact[l]\n",
    "    )\n",
    "\n",
    "    # Define the constraints\n",
    "    if demand_reduction_equals:\n",
    "        model.demand_reduction = Constraint(\n",
    "            expr=sum(model.decision[act] for act in model.activities)\n",
    "            == demand_reduction\n",
    "        )\n",
    "    else:\n",
    "        model.demand_reduction = Constraint(\n",
    "            expr=sum(model.decision[act] for act in model.activities)\n",
    "            <= demand_reduction\n",
    "        )\n",
    "\n",
    "    model.power_plants = Constraint(\n",
    "        expr=model.decision[\"Coal-fired power plants\"]\n",
    "        + model.decision[\"Oil-fired power plants\"]\n",
    "        + model.decision[\"Nuclear power\"]\n",
    "        + model.decision[\"Solar power\"]\n",
    "        + model.decision[\"Wind power\"]\n",
    "        + model.decision[\"Hydro power\"]\n",
    "        + model.decision[\"Electricity savings\"]\n",
    "        <= 50\n",
    "    )\n",
    "    model.chp = Constraint(\n",
    "        expr=model.decision[\"Coal-fired CHP\"]\n",
    "        + model.decision[\"Oil-fired CHP\"]\n",
    "        + model.decision[\"Biomass-fired CHP\"]\n",
    "        <= 62.1 + 8.1\n",
    "    )\n",
    "    model.industry = Constraint(\n",
    "        expr=model.decision[\"Coal-based industrial heating\"]\n",
    "        + model.decision[\"Oil-based industrial heating\"]\n",
    "        + model.decision[\n",
    "            \"Industrial heating savings\\\\n(improved efficiency,\\\\nproduction curtailment)\"\n",
    "        ]\n",
    "        <= 110.4\n",
    "    )\n",
    "    model.household = Constraint(\n",
    "        expr=model.decision[\"Heat pumps (household)\"]\n",
    "        + model.decision[\n",
    "            \"Heat savings (mild winter,\\\\nefficiency improvements,\\\\nbehavior change)\"\n",
    "        ]\n",
    "        <= 153.9\n",
    "    )\n",
    "\n",
    "    if constrain_savings:\n",
    "        savings = [\n",
    "            r\"Electricity savings\",\n",
    "            r\"Industrial heating savings\\n(improved efficiency,\\nproduction curtailment)\",\n",
    "            r\"Heat savings (mild winter,\\nefficiency improvements,\\nbehavior change)\",\n",
    "        ]\n",
    "        label_savings = [\n",
    "            r\"electricity_savings\",\n",
    "            r\"curtailment\",\n",
    "            r\"heat_savings\",\n",
    "        ]\n",
    "        for l, s in zip(label_savings, savings):\n",
    "            model.__setattr__(l, Constraint(expr=model.decision[s] == 0))\n",
    "\n",
    "    if limit_each_to is not None:\n",
    "        for act in model.activities:\n",
    "            model.__setattr__(\n",
    "                act, Constraint(expr=model.decision[act] <= limit_each_to)\n",
    "            )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def check_print_opt_results(res, model):\n",
    "    assert res[\"Solver\"][0][\"Status\"] == SolverStatus.ok\n",
    "\n",
    "    ovr = res[\"Problem\"][0]\n",
    "    assert (\n",
    "        abs(ovr[\"Lower bound\"] - ovr[\"Upper bound\"]) / (ovr[\"Lower bound\"] + 1e-12)\n",
    "        < 1e-3\n",
    "    )\n",
    "\n",
    "    print(\"Objective value:\", model.objective())\n",
    "    model.objective.pprint()\n",
    "    model.decision.pprint()\n",
    "\n",
    "\n",
    "stat_relevant_cols_opt = copy.copy(stat_relevant_cols)\n",
    "stat_relevant_cols_opt = copy.copy(df_sens_analysis_pct_pb.columns.tolist())\n",
    "\n",
    "\n",
    "def process_opt_lca_result(model, df_pct, pb_base=None):\n",
    "    decision_results = {k: v.value for k, v in model.decision.items()}\n",
    "    df_decisions = pd.Series(decision_results)\n",
    "\n",
    "    df_alternative = df_decisions * df_pct[stat_relevant_cols_opt].T\n",
    "    df_alternative.dropna(how=\"all\", axis=1, inplace=True)\n",
    "    assert df_alternative.isna().sum().sum() == 0\n",
    "\n",
    "    lca_soln = (\n",
    "        df_alternative.sum(axis=1)\n",
    "        + df_pct.loc[r\"$\\Delta$NG Year 2022\", stat_relevant_cols_opt]\n",
    "    )\n",
    "\n",
    "    lca_soln = lca_soln if pb_base is None else (lca_soln + pb_base) * 100\n",
    "\n",
    "    obj_calcd = lca_soln.map(lambda x: max(x, 0)).sum() / len(df_pct.columns)\n",
    "\n",
    "    print(\"Objective value calculated:\", obj_calcd)\n",
    "    print(\"Objective value from model:\", model.objective(), \"\\n\")\n",
    "    # assert abs(obj_calcd - model.objective()) / obj_calcd < 1e-3\n",
    "\n",
    "    print(lca_soln.sort_values(ascending=False))\n",
    "\n",
    "    return lca_soln\n",
    "\n",
    "\n",
    "df_sens_analysis_pct_ = df_sens_analysis_pct[stat_relevant_cols_opt].copy()\n",
    "# df_sens_analysis_pct_ = df_sens_analysis_pct_\n",
    "\n",
    "df_sens_analysis_pct_pb_ = df_sens_analysis_pct_pb[stat_relevant_cols_opt].copy()\n",
    "# df_sens_analysis_pct_pb_[df_sens_analysis_pct_pb.columns.str.replace(\",\", \"\")] = (\n",
    "#     df_sens_analysis_pct_pb.values\n",
    "# )\n",
    "# df_sens_analysis_pct_pb_ = df_sens_analysis_pct_pb_\n",
    "\n",
    "pb_base = df_ef_pb.loc[SCENARIOS[0], :].values / 100\n",
    "\n",
    "\n",
    "def run_all_opt_analysis(\n",
    "    df_pct,\n",
    "    demand_reduction=50,\n",
    "    constrain_savings=True,\n",
    "    pb_base=None,\n",
    "    limit_each_to=None,\n",
    "    demand_reduction_equals=True,\n",
    "    ax=None,\n",
    "    fig=None,\n",
    "):\n",
    "    # Solve the model 50bcm & constrain savings\n",
    "    model = instantiating_model(\n",
    "        df_pct,\n",
    "        demand_reduction=demand_reduction,\n",
    "        constrain_savings=constrain_savings,\n",
    "        pb_base=pb_base,\n",
    "        limit_each_to=limit_each_to,\n",
    "        demand_reduction_equals=demand_reduction_equals,\n",
    "    )\n",
    "    solver = SolverFactory(\"cplex\")\n",
    "\n",
    "    opt_results = solver.solve(model, tee=False, report_timing=False)\n",
    "    check_print_opt_results(opt_results, model)\n",
    "    lca_soln = process_opt_lca_result(model, df_pct, pb_base=pb_base)\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    pd.DataFrame(lca_soln, columns=[\"Optimum\"]).sort_values(by=\"Optimum\").plot(\n",
    "        kind=\"barh\", ax=ax\n",
    "    )\n",
    "\n",
    "    return model, opt_results, lca_soln, fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE\n",
    "model, opt_results, lca_soln, fig, ax = run_all_opt_analysis(\n",
    "    df_sens_analysis_pct_,\n",
    "    demand_reduction=0,\n",
    "    constrain_savings=True,\n",
    "    pb_base=pb_base,\n",
    "    limit_each_to=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 bcm target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the model 50bcm & constrain savings\n",
    "model, opt_results, lca_soln, fig, ax = run_all_opt_analysis(\n",
    "    df_sens_analysis_pct_,\n",
    "    demand_reduction=50,\n",
    "    constrain_savings=True,\n",
    "    pb_base=None,\n",
    "    limit_each_to=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the model 50bcm & constrain savings\n",
    "model, opt_results, lca_soln, fig, ax = run_all_opt_analysis(\n",
    "    df_sens_analysis_pct_,\n",
    "    demand_reduction=50,\n",
    "    constrain_savings=True,\n",
    "    pb_base=None,\n",
    "    limit_each_to=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the model 50bcm & not constraint savings & PB\n",
    "model, opt_results, lca_soln, fig, ax = run_all_opt_analysis(\n",
    "    df_sens_analysis_pct_pb_,\n",
    "    demand_reduction=50,\n",
    "    pb_base=pb_base,\n",
    "    constrain_savings=False,\n",
    "    limit_each_to=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the model 50bcm & constrain savings & PB\n",
    "model, opt_results, lca_soln, fig, ax = run_all_opt_analysis(\n",
    "    df_sens_analysis_pct_pb_,\n",
    "    demand_reduction=50,\n",
    "    constrain_savings=True,\n",
    "    pb_base=pb_base,\n",
    "    limit_each_to=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >100 bcm targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the model 150bcm & constrain savings\n",
    "model, opt_results, lca_soln, fig, ax = run_all_opt_analysis(\n",
    "    df_sens_analysis_pct_,\n",
    "    demand_reduction=150,\n",
    "    constrain_savings=True,\n",
    "    pb_base=None,\n",
    "    limit_each_to=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the model 150bcm & constrain savings & PB\n",
    "model, opt_results, lca_soln, fig, ax = run_all_opt_analysis(\n",
    "    df_sens_analysis_pct_pb_,\n",
    "    demand_reduction=150,\n",
    "    constrain_savings=True,\n",
    "    pb_base=pb_base,\n",
    "    limit_each_to=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the model 400bcm & constrain savings & PB\n",
    "model, opt_results, lca_soln, fig, ax = run_all_opt_analysis(\n",
    "    df_sens_analysis_pct_pb_,\n",
    "    demand_reduction=384,\n",
    "    constrain_savings=True,\n",
    "    pb_base=pb_base,\n",
    "    limit_each_to=None,\n",
    "    demand_reduction_equals=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the model 400bcm & constrain savings & PB\n",
    "model, opt_results, lca_soln, fig, ax = run_all_opt_analysis(\n",
    "    df_sens_analysis_pct_pb_,\n",
    "    demand_reduction=400,\n",
    "    constrain_savings=True,\n",
    "    pb_base=pb_base,\n",
    "    limit_each_to=None,\n",
    "    demand_reduction_equals=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
